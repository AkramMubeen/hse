{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4152163f-e073-461b-b2f3-091f8ebf6b7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# ML Experiment 1 - HSE CC PQ Incidents Prediction (June '25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e06b4b1-581e-4680-91b8-ce6eb0a649b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0e322c3-0774-4e25-8f5f-e2b8e73b9df8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.3\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e4bf303-4f76-4e44-a14e-d3e0d92e1b3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (24.0)\r\nCollecting pip\r\n  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\r\nDownloading pip-25.1.1-py3-none-any.whl (1.8 MB)\r\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/1.8 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m1.8/1.8 MB\u001B[0m \u001B[31m56.5 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.8/1.8 MB\u001B[0m \u001B[31m33.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n\u001B[?25hInstalling collected packages: pip\r\n  Attempting uninstall: pip\r\n    Found existing installation: pip 24.0\r\n    Uninstalling pip-24.0:\r\n      Successfully uninstalled pip-24.0\r\nSuccessfully installed pip-25.1.1\r\n\u001B[33mDEPRECATION: Using the pkg_resources metadata backend is deprecated. pip 26.3 will enforce this behaviour change. A possible replacement is to use the default importlib.metadata backend, by unsetting the _PIP_USE_IMPORTLIB_METADATA environment variable. Discussion can be found at https://github.com/pypa/pip/issues/13317\u001B[0m\u001B[33m\r\n\u001B[0mCollecting autogluon\r\n  Downloading autogluon-1.3.1-py3-none-any.whl.metadata (11 kB)\r\nCollecting imbalanced-learn\r\n  Downloading imbalanced_learn-0.13.0-py3-none-any.whl.metadata (8.8 kB)\r\nCollecting loguru\r\n  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\r\nCollecting autogluon.core==1.3.1 (from autogluon.core[all]==1.3.1->autogluon)\r\n  Downloading autogluon.core-1.3.1-py3-none-any.whl.metadata (12 kB)\r\nCollecting autogluon.features==1.3.1 (from autogluon)\r\n  Downloading autogluon.features-1.3.1-py3-none-any.whl.metadata (11 kB)\r\nCollecting autogluon.tabular==1.3.1 (from autogluon.tabular[all]==1.3.1->autogluon)\r\n  Downloading autogluon.tabular-1.3.1-py3-none-any.whl.metadata (14 kB)\r\nCollecting autogluon.multimodal==1.3.1 (from autogluon)\r\n  Downloading autogluon.multimodal-1.3.1-py3-none-any.whl.metadata (13 kB)\r\nCollecting autogluon.timeseries==1.3.1 (from autogluon.timeseries[all]==1.3.1->autogluon)\r\n  Downloading autogluon.timeseries-1.3.1-py3-none-any.whl.metadata (12 kB)\r\nRequirement already satisfied: numpy<2.3.0,>=1.25.0 in /databricks/python3/lib/python3.12/site-packages (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (1.26.4)\r\nRequirement already satisfied: scipy<1.16,>=1.5.4 in /databricks/python3/lib/python3.12/site-packages (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (1.13.1)\r\nRequirement already satisfied: scikit-learn<1.7.0,>=1.4.0 in /databricks/python3/lib/python3.12/site-packages (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (1.4.2)\r\nCollecting networkx<4,>=3.0 (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon)\r\n  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\r\nCollecting pandas<2.3.0,>=2.0.0 (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon)\r\n  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\r\nCollecting tqdm<5,>=4.38 (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon)\r\n  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\r\nRequirement already satisfied: requests in /databricks/python3/lib/python3.12/site-packages (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (2.32.2)\r\nRequirement already satisfied: matplotlib<3.11,>=3.7.0 in /databricks/python3/lib/python3.12/site-packages (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (3.8.4)\r\nRequirement already satisfied: boto3<2,>=1.10 in /databricks/python3/lib/python3.12/site-packages (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (1.34.69)\r\nCollecting autogluon.common==1.3.1 (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon)\r\n  Downloading autogluon.common-1.3.1-py3-none-any.whl.metadata (11 kB)\r\nRequirement already satisfied: psutil<7.1.0,>=5.7.3 in /databricks/python3/lib/python3.12/site-packages (from autogluon.common==1.3.1->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (5.9.0)\r\nCollecting ray<2.45,>=2.10.0 (from ray[default]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\r\n  Downloading ray-2.44.1-cp312-cp312-manylinux2014_x86_64.whl.metadata (19 kB)\r\nCollecting hyperopt<0.2.8,>=0.2.7 (from autogluon.core[all]==1.3.1->autogluon)\r\n  Downloading hyperopt-0.2.7-py2.py3-none-any.whl.metadata (1.7 kB)\r\nRequirement already satisfied: pyarrow>=15.0.0 in /databricks/python3/lib/python3.12/site-packages (from autogluon.core[all]==1.3.1->autogluon) (15.0.2)\r\nRequirement already satisfied: Pillow<12,>=10.0.1 in /databricks/python3/lib/python3.12/site-packages (from autogluon.multimodal==1.3.1->autogluon) (10.3.0)\r\nCollecting torch<2.7,>=2.2 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading torch-2.6.0-cp312-cp312-manylinux1_x86_64.whl.metadata (28 kB)\r\nCollecting lightning<2.7,>=2.2 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading lightning-2.5.2-py3-none-any.whl.metadata (38 kB)\r\nCollecting transformers<4.50,>=4.38.0 (from transformers[sentencepiece]<4.50,>=4.38.0->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\r\nCollecting accelerate<2.0,>=0.34.0 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading accelerate-1.8.1-py3-none-any.whl.metadata (19 kB)\r\nCollecting jsonschema<4.24,>=4.18 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\r\nCollecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\r\n  Preparing metadata (setup.py) ... \u001B[?25l-\b \b\\\b \b|\b \bdone\r\n\u001B[?25hCollecting evaluate<0.5.0,>=0.4.0 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading evaluate-0.4.4-py3-none-any.whl.metadata (9.5 kB)\r\nCollecting timm<1.0.7,>=0.9.5 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading timm-1.0.3-py3-none-any.whl.metadata (43 kB)\r\nCollecting torchvision<0.22.0,>=0.16.0 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading torchvision-0.21.0-cp312-cp312-manylinux1_x86_64.whl.metadata (6.1 kB)\r\nCollecting scikit-image<0.26.0,>=0.19.1 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading scikit_image-0.25.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\r\nCollecting text-unidecode<1.4,>=1.3 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\r\nCollecting torchmetrics<1.8,>=1.2.0 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading torchmetrics-1.7.3-py3-none-any.whl.metadata (21 kB)\r\nCollecting omegaconf<2.4.0,>=2.1.1 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\r\nCollecting pytorch-metric-learning<2.9,>=1.3.0 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl.metadata (18 kB)\r\nCollecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\r\nCollecting nltk<3.9,>=3.4.5 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\r\nCollecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\r\nCollecting defusedxml<0.7.2,>=0.7.1 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\r\nCollecting jinja2<3.2,>=3.0.3 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\r\nCollecting tensorboard<3,>=2.9 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\r\nCollecting pytesseract<0.4,>=0.3.9 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\r\nCollecting nvidia-ml-py3<8.0,>=7.352.0 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\r\n  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n\u001B[?25hCollecting pdf2image<1.19,>=1.17.0 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\r\nCollecting catboost<1.3,>=1.2 (from autogluon.tabular[all]==1.3.1->autogluon)\r\n  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\r\nCollecting einops<0.9,>=0.7 (from autogluon.tabular[all]==1.3.1->autogluon)\r\n  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\r\nCollecting xgboost<3.1,>=2.0 (from autogluon.tabular[all]==1.3.1->autogluon)\r\n  Downloading xgboost-3.0.2-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\r\nCollecting fastai<2.9,>=2.3.1 (from autogluon.tabular[all]==1.3.1->autogluon)\r\n  Downloading fastai-2.8.2-py3-none-any.whl.metadata (9.5 kB)\r\nCollecting huggingface-hub[torch] (from autogluon.tabular[all]==1.3.1->autogluon)\r\n  Downloading huggingface_hub-0.33.0-py3-none-any.whl.metadata (14 kB)\r\nCollecting lightgbm<4.7,>=4.0 (from autogluon.tabular[all]==1.3.1->autogluon)\r\n  Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl.metadata (17 kB)\r\nCollecting spacy<3.9 (from autogluon.tabular[all]==1.3.1->autogluon)\r\n  Downloading spacy-3.8.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\r\nRequirement already satisfied: joblib<2,>=1.1 in /databricks/python3/lib/python3.12/site-packages (from autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (1.4.2)\r\nCollecting pytorch-lightning (from autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\r\n  Downloading pytorch_lightning-2.5.2-py3-none-any.whl.metadata (21 kB)\r\nCollecting gluonts<0.17,>=0.15.0 (from autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\r\n  Downloading gluonts-0.16.1-py3-none-any.whl.metadata (9.8 kB)\r\nCollecting statsforecast<2.0.2,>=1.7.0 (from autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\r\n  Downloading statsforecast-2.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (29 kB)\r\nCollecting mlforecast<0.14,>0.13 (from autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\r\n  Downloading mlforecast-0.13.6-py3-none-any.whl.metadata (12 kB)\r\nCollecting utilsforecast<0.2.11,>=0.2.3 (from autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\r\n  Downloading utilsforecast-0.2.10-py3-none-any.whl.metadata (7.4 kB)\r\nCollecting coreforecast<0.0.16,>=0.0.12 (from autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\r\n  Downloading coreforecast-0.0.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\r\nCollecting fugue>=0.9.0 (from autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\r\n  Downloading fugue-0.9.1-py3-none-any.whl.metadata (18 kB)\r\nCollecting orjson~=3.9 (from autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\r\n  Downloading orjson-3.10.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\r\nRequirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.12/site-packages (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.3.1->autogluon) (24.1)\r\nRequirement already satisfied: pyyaml in /databricks/python3/lib/python3.12/site-packages (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.3.1->autogluon) (6.0.1)\r\nCollecting safetensors>=0.4.3 (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\r\nRequirement already satisfied: botocore<1.35.0,>=1.34.69 in /databricks/python3/lib/python3.12/site-packages (from boto3<2,>=1.10->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (1.34.69)\r\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /databricks/python3/lib/python3.12/site-packages (from boto3<2,>=1.10->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (1.0.1)\r\nRequirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /databricks/python3/lib/python3.12/site-packages (from boto3<2,>=1.10->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (0.10.2)\r\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /databricks/python3/lib/python3.12/site-packages (from botocore<1.35.0,>=1.34.69->boto3<2,>=1.10->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (2.9.0.post0)\r\nRequirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /databricks/python3/lib/python3.12/site-packages (from botocore<1.35.0,>=1.34.69->boto3<2,>=1.10->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (1.26.16)\r\nCollecting graphviz (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.3.1->autogluon)\r\n  Downloading graphviz-0.21-py3-none-any.whl.metadata (12 kB)\r\nRequirement already satisfied: plotly in /databricks/python3/lib/python3.12/site-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.3.1->autogluon) (5.22.0)\r\nRequirement already satisfied: six in /usr/lib/python3/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.3.1->autogluon) (1.16.0)\r\nCollecting datasets>=2.0.0 (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\r\nCollecting dill (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\r\nCollecting xxhash (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\r\nCollecting multiprocess (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading multiprocess-0.70.18-py312-none-any.whl.metadata (7.5 kB)\r\nCollecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\r\nRequirement already satisfied: pip in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.3.1->autogluon) (25.1.1)\r\nCollecting fastdownload<2,>=0.0.5 (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.3.1->autogluon)\r\n  Downloading fastdownload-0.0.7-py3-none-any.whl.metadata (5.5 kB)\r\nCollecting fastcore<1.9,>=1.8.0 (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.3.1->autogluon)\r\n  Downloading fastcore-1.8.4-py3-none-any.whl.metadata (3.7 kB)\r\nCollecting fasttransform>=0.0.2 (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.3.1->autogluon)\r\n  Downloading fasttransform-0.0.2-py3-none-any.whl.metadata (7.6 kB)\r\nCollecting fastprogress>=0.2.4 (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.3.1->autogluon)\r\n  Downloading fastprogress-1.0.3-py3-none-any.whl.metadata (5.6 kB)\r\nCollecting plum-dispatch (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.3.1->autogluon)\r\n  Downloading plum_dispatch-2.5.7-py3-none-any.whl.metadata (7.5 kB)\r\nRequirement already satisfied: cloudpickle in /databricks/python3/lib/python3.12/site-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.3.1->autogluon) (2.2.1)\r\nRequirement already satisfied: pydantic<3,>=1.7 in /databricks/python3/lib/python3.12/site-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (2.8.2)\r\nCollecting toolz~=0.10 (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\r\n  Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\r\nRequirement already satisfied: typing-extensions~=4.0 in /databricks/python3/lib/python3.12/site-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (4.11.0)\r\nCollecting future (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.3.1->autogluon)\r\n  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\r\nCollecting py4j (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.3.1->autogluon)\r\n  Downloading py4j-0.10.9.9-py2.py3-none-any.whl.metadata (1.3 kB)\r\nCollecting MarkupSafe>=2.0 (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\r\nCollecting attrs>=22.2.0 (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\r\nCollecting jsonschema-specifications>=2023.03.6 (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\r\nCollecting referencing>=0.28.4 (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\r\nCollecting rpds-py>=0.7.1 (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading rpds_py-0.25.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\r\nCollecting lightning-utilities<2.0,>=0.10.0 (from lightning<2.7,>=2.2->autogluon.multimodal==1.3.1->autogluon)\r\n  Using cached lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\r\nCollecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>=2021.05.0->evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading aiohttp-3.12.13-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\r\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning<2.7,>=2.2->autogluon.multimodal==1.3.1->autogluon) (74.0.0)\r\nRequirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (1.2.0)\r\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (0.11.0)\r\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (4.51.0)\r\nRequirement already satisfied: kiwisolver>=1.3.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (1.4.4)\r\nRequirement already satisfied: pyparsing>=2.3.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (3.0.9)\r\nCollecting numba (from mlforecast<0.14,>0.13->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\r\n  Downloading numba-0.61.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\r\nCollecting optuna (from mlforecast<0.14,>0.13->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\r\n  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\r\nCollecting window-ops (from mlforecast<0.14,>0.13->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\r\n  Downloading window_ops-0.0.15-py3-none-any.whl.metadata (6.8 kB)\r\nCollecting gdown>=4.0.0 (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\r\nRequirement already satisfied: click in /databricks/python3/lib/python3.12/site-packages (from nltk<3.9,>=3.4.5->autogluon.multimodal==1.3.1->autogluon) (8.1.7)\r\nCollecting regex>=2021.8.3 (from nltk<3.9,>=3.4.5->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\r\nCollecting antlr4-python3-runtime==4.9.* (from omegaconf<2.4.0,>=2.1.1->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\r\n  Preparing metadata (setup.py) ... \u001B[?25l-\b \bdone\r\n\u001B[?25hCollecting colorama (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\r\nCollecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\r\nCollecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\r\nCollecting rich (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\r\nCollecting tabulate (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\r\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.12/site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (2024.1)\r\nCollecting tzdata>=2022.7 (from pandas<2.3.0,>=2.0.0->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon)\r\n  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\r\nRequirement already satisfied: annotated-types>=0.4.0 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (0.7.0)\r\nRequirement already satisfied: pydantic-core==2.20.1 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (2.20.1)\r\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from ray<2.45,>=2.10.0->ray[default]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (3.15.4)\r\nCollecting msgpack<2.0.0,>=1.0.0 (from ray<2.45,>=2.10.0->ray[default]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\r\n  Downloading msgpack-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\r\nRequirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /databricks/python3/lib/python3.12/site-packages (from ray<2.45,>=2.10.0->ray[default]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (4.24.1)\r\nCollecting aiosignal (from ray<2.45,>=2.10.0->ray[default]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\r\n  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\r\nCollecting frozenlist (from ray<2.45,>=2.10.0->ray[default]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\r\n  Downloading frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\r\nCollecting aiohttp_cors (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\r\n  Downloading aiohttp_cors-0.8.1-py3-none-any.whl.metadata (20 kB)\r\nCollecting colorful (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\r\n  Downloading colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)\r\nCollecting py-spy>=0.4.0 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\r\n  Downloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (16 kB)\r\nRequirement already satisfied: grpcio>=1.42.0 in /databricks/python3/lib/python3.12/site-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (1.60.0)\r\nCollecting opencensus (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\r\n  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\r\nCollecting prometheus_client>=0.7.1 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\r\n  Downloading prometheus_client-0.22.1-py3-none-any.whl.metadata (1.9 kB)\r\nCollecting smart_open (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\r\n  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\r\nRequirement already satisfied: virtualenv!=20.21.1,>=20.0.24 in /usr/local/lib/python3.12/dist-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (20.26.2)\r\nCollecting tensorboardX>=1.9 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\r\n  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\r\nRequirement already satisfied: charset-normalizer<4,>=2 in /data\n\n*** WARNING: max output size exceeded, skipping output. ***\n\n  \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━\u001B[0m \u001B[32m14/17\u001B[0m [ray]\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━\u001B[0m \u001B[32m14/17\u001B[0m [ray]\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━\u001B[0m \u001B[32m14/17\u001B[0m [ray]\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━\u001B[0m \u001B[32m14/17\u001B[0m [ray]\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━\u001B[0m \u001B[32m14/17\u001B[0m [ray]\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━\u001B[0m \u001B[32m14/17\u001B[0m [ray]\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━\u001B[0m \u001B[32m14/17\u001B[0m [ray]\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━\u001B[0m \u001B[32m14/17\u001B[0m [ray]\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━\u001B[0m \u001B[32m14/17\u001B[0m [ray]\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━\u001B[0m \u001B[32m14/17\u001B[0m [ray]\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━\u001B[0m \u001B[32m15/17\u001B[0m [fastapi]\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━\u001B[0m \u001B[32m16/17\u001B[0m [memray]\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━\u001B[0m \u001B[32m16/17\u001B[0m [memray]\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━\u001B[0m \u001B[32m16/17\u001B[0m [memray]\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m17/17\u001B[0m [memray]\n\u001B[?25h\n\u001B[1A\u001B[2KSuccessfully installed anyio-4.9.0 fastapi-0.115.13 h11-0.16.0 httptools-0.6.4 linkify-it-py-2.0.3 mdit-py-plugins-0.4.2 memray-1.17.2 python-dotenv-1.1.0 ray-2.39.0 sniffio-1.3.1 starlette-0.46.2 textual-3.5.0 uc-micro-py-1.0.3 uvicorn-0.34.3 uvloop-0.21.0 watchfiles-1.1.0 websockets-15.0.1\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[33mDEPRECATION: Using the pkg_resources metadata backend is deprecated. pip 26.3 will enforce this behaviour change. A possible replacement is to use the default importlib.metadata backend, by unsetting the _PIP_USE_IMPORTLIB_METADATA environment variable. Discussion can be found at https://github.com/pypa/pip/issues/13317\u001B[0m\u001B[33m\r\n\u001B[0mLooking in indexes: https://download.pytorch.org/whl/cpu\r\nRequirement already satisfied: torch in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (2.6.0)\r\nRequirement already satisfied: torchvision in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (0.21.0)\r\nCollecting torchaudio\r\n  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.7.1%2Bcpu-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\r\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.15.4)\r\nRequirement already satisfied: typing-extensions>=4.10.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from torch) (4.14.0)\r\nRequirement already satisfied: networkx in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from torch) (3.5)\r\nRequirement already satisfied: jinja2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from torch) (3.1.6)\r\nRequirement already satisfied: fsspec in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from torch) (2025.5.1)\r\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from torch) (12.4.127)\r\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from torch) (12.4.127)\r\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from torch) (12.4.127)\r\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from torch) (9.1.0.70)\r\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from torch) (12.4.5.8)\r\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from torch) (11.2.1.3)\r\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from torch) (10.3.5.147)\r\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from torch) (11.6.1.9)\r\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from torch) (12.3.1.170)\r\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from torch) (0.6.2)\r\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from torch) (2.21.5)\r\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from torch) (12.4.127)\r\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from torch) (12.4.127)\r\nRequirement already satisfied: triton==3.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from torch) (3.2.0)\r\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (74.0.0)\r\nRequirement already satisfied: sympy==1.13.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from torch) (1.13.1)\r\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\r\nRequirement already satisfied: numpy in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from torchvision) (2.1.3)\r\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /databricks/python3/lib/python3.12/site-packages (from torchvision) (10.3.0)\r\nINFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\r\n  Using cached https://download.pytorch.org/whl/cpu/torchaudio-2.7.0%2Bcpu-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\r\n  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.6.0%2Bcpu-cp312-cp312-linux_x86_64.whl.metadata (6.6 kB)\r\nRequirement already satisfied: MarkupSafe>=2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\r\nUsing cached https://download.pytorch.org/whl/cpu/torchaudio-2.6.0%2Bcpu-cp312-cp312-linux_x86_64.whl (1.7 MB)\r\nInstalling collected packages: torchaudio\r\nSuccessfully installed torchaudio-2.6.0+cpu\r\n\u001B[33mDEPRECATION: Using the pkg_resources metadata backend is deprecated. pip 26.3 will enforce this behaviour change. A possible replacement is to use the default importlib.metadata backend, by unsetting the _PIP_USE_IMPORTLIB_METADATA environment variable. Discussion can be found at https://github.com/pypa/pip/issues/13317\u001B[0m\u001B[33m\n\u001B[0mCollecting fastai==2.7.19\n  Downloading fastai-2.7.19-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: pip in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from fastai==2.7.19) (25.1.1)\nRequirement already satisfied: packaging in /databricks/python3/lib/python3.12/site-packages (from fastai==2.7.19) (24.1)\nRequirement already satisfied: fastdownload<2,>=0.0.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from fastai==2.7.19) (0.0.7)\nCollecting fastcore<1.8,>=1.5.29 (from fastai==2.7.19)\n  Downloading fastcore-1.7.29-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: torchvision>=0.11 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from fastai==2.7.19) (0.21.0)\nRequirement already satisfied: matplotlib in /databricks/python3/lib/python3.12/site-packages (from fastai==2.7.19) (3.8.4)\nRequirement already satisfied: pandas in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from fastai==2.7.19) (2.2.3)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.12/site-packages (from fastai==2.7.19) (2.32.2)\nRequirement already satisfied: pyyaml in /databricks/python3/lib/python3.12/site-packages (from fastai==2.7.19) (6.0.1)\nRequirement already satisfied: fastprogress>=0.2.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from fastai==2.7.19) (1.0.3)\nRequirement already satisfied: pillow>=9.0.0 in /databricks/python3/lib/python3.12/site-packages (from fastai==2.7.19) (10.3.0)\nRequirement already satisfied: scikit-learn in /databricks/python3/lib/python3.12/site-packages (from fastai==2.7.19) (1.4.2)\nRequirement already satisfied: scipy in /databricks/python3/lib/python3.12/site-packages (from fastai==2.7.19) (1.13.1)\nRequirement already satisfied: spacy<4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from fastai==2.7.19) (3.8.7)\nRequirement already satisfied: torch<2.7,>=1.10 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from fastai==2.7.19) (2.6.0)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from spacy<4->fastai==2.7.19) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from spacy<4->fastai==2.7.19) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from spacy<4->fastai==2.7.19) (1.0.13)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from spacy<4->fastai==2.7.19) (2.0.11)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from spacy<4->fastai==2.7.19) (3.0.10)\nRequirement already satisfied: thinc<8.4.0,>=8.3.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from spacy<4->fastai==2.7.19) (8.3.6)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from spacy<4->fastai==2.7.19) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from spacy<4->fastai==2.7.19) (2.5.1)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from spacy<4->fastai==2.7.19) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from spacy<4->fastai==2.7.19) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from spacy<4->fastai==2.7.19) (0.16.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from spacy<4->fastai==2.7.19) (4.67.1)\nRequirement already satisfied: numpy>=1.19.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from spacy<4->fastai==2.7.19) (2.1.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /databricks/python3/lib/python3.12/site-packages (from spacy<4->fastai==2.7.19) (2.8.2)\nRequirement already satisfied: jinja2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from spacy<4->fastai==2.7.19) (3.1.6)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy<4->fastai==2.7.19) (74.0.0)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from spacy<4->fastai==2.7.19) (3.5.0)\nRequirement already satisfied: language-data>=1.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<4->fastai==2.7.19) (1.3.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /databricks/python3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai==2.7.19) (0.7.0)\nRequirement already satisfied: pydantic-core==2.20.1 in /databricks/python3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai==2.7.19) (2.20.1)\nRequirement already satisfied: typing-extensions>=4.6.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai==2.7.19) (4.14.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.12/site-packages (from requests->fastai==2.7.19) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.12/site-packages (from requests->fastai==2.7.19) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.12/site-packages (from requests->fastai==2.7.19) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.12/site-packages (from requests->fastai==2.7.19) (2024.6.2)\nRequirement already satisfied: blis<1.4.0,>=1.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy<4->fastai==2.7.19) (1.3.0)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy<4->fastai==2.7.19) (0.1.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<2.7,>=1.10->fastai==2.7.19) (3.15.4)\nRequirement already satisfied: networkx in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from torch<2.7,>=1.10->fastai==2.7.19) (3.5)\nRequirement already satisfied: fsspec in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from torch<2.7,>=1.10->fastai==2.7.19) (2025.5.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from torch<2.7,>=1.10->fastai==2.7.19) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from torch<2.7,>=1.10->fastai==2.7.19) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from torch<2.7,>=1.10->fastai==2.7.19) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from torch<2.7,>=1.10->fastai==2.7.19) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from torch<2.7,>=1.10->fastai==2.7.19) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from torch<2.7,>=1.10->fastai==2.7.19) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from torch<2.7,>=1.10->fastai==2.7.19) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from torch<2.7,>=1.10->fastai==2.7.19) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from torch<2.7,>=1.10->fastai==2.7.19) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from torch<2.7,>=1.10->fastai==2.7.19) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from torch<2.7,>=1.10->fastai==2.7.19) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from torch<2.7,>=1.10->fastai==2.7.19) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from torch<2.7,>=1.10->fastai==2.7.19) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from torch<2.7,>=1.10->fastai==2.7.19) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from torch<2.7,>=1.10->fastai==2.7.19) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from sympy==1.13.1->torch<2.7,>=1.10->fastai==2.7.19) (1.3.0)\nRequirement already satisfied: click>=8.0.0 in /databricks/python3/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai==2.7.19) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai==2.7.19) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai==2.7.19) (14.0.0)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai==2.7.19) (0.21.1)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai==2.7.19) (7.1.0)\nRequirement already satisfied: wrapt in /databricks/python3/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<4->fastai==2.7.19) (1.14.1)\nRequirement already satisfied: marisa-trie>=1.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4->fastai==2.7.19) (1.2.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai==2.7.19) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /databricks/python3/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai==2.7.19) (2.15.1)\nRequirement already satisfied: mdurl~=0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai==2.7.19) (0.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from jinja2->spacy<4->fastai==2.7.19) (3.0.2)\nRequirement already satisfied: contourpy>=1.0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from matplotlib->fastai==2.7.19) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.12/site-packages (from matplotlib->fastai==2.7.19) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.12/site-packages (from matplotlib->fastai==2.7.19) (4.51.0)\nRequirement already satisfied: kiwisolver>=1.3.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib->fastai==2.7.19) (1.4.4)\nRequirement already satisfied: pyparsing>=2.3.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib->fastai==2.7.19) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /databricks/python3/lib/python3.12/site-packages (from matplotlib->fastai==2.7.19) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib->fastai==2.7.19) (1.16.0)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.12/site-packages (from pandas->fastai==2.7.19) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from pandas->fastai==2.7.19) (2025.2)\nRequirement already satisfied: joblib>=1.2.0 in /databricks/python3/lib/python3.12/site-packages (from scikit-learn->fastai==2.7.19) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages (from scikit-learn->fastai==2.7.19) (3.6.0)\nDownloading fastai-2.7.19-py3-none-any.whl (234 kB)\nDownloading fastcore-1.7.29-py3-none-any.whl (84 kB)\nInstalling collected packages: fastcore, fastai\n\u001B[?25l\n\u001B[2K  Attempting uninstall: fastcore\n\n\u001B[2K    Found existing installation: fastcore 1.8.4\n\n\u001B[2K    Uninstalling fastcore-1.8.4:\n\n\u001B[2K      Successfully uninstalled fastcore-1.8.4\n\n\u001B[2K  Attempting uninstall: fastai\n\n\u001B[2K    Found existing installation: fastai 2.8.2\n\n\u001B[2K    Uninstalling fastai-2.8.2:\n\n\u001B[2K      Successfully uninstalled fastai-2.8.2\n\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1/2\u001B[0m [fastai]\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1/2\u001B[0m [fastai]\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2/2\u001B[0m [fastai]\n\u001B[?25h\n\u001B[1A\u001B[2KSuccessfully installed fastai-2.7.19 fastcore-1.7.29\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --upgrade pip\n",
    "!python -m pip install autogluon imbalanced-learn loguru\n",
    "!pip install -U ray[data,train,tune,serve]==2.39.0\n",
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install -U fastai==2.7.19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b903f91-4f95-4105-8a1d-d0ca72ef4c2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "271677db-fa0c-4eef-b27d-572d8236ab42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow; mlflow.autolog(disable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43967473-9f4c-4918-8364-b2ea8353a234",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from loguru import logger\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4344f5d-506a-4dde-adcd-8c658585f0a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Classification with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc6313cf-f69d-4419-831a-a462e0240d9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-06-23 06:05:12.589\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m32\u001B[0m - \u001B[1mTrain data shape: (3949, 26)\u001B[0m\n\u001B[32m2025-06-23 06:05:12.590\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m33\u001B[0m - \u001B[1mTest data shape: (1693, 26)\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# Load ML dataset\n",
    "ml_df_class = spark.table('hive_metastore.default.hse_cc_pred_ml_2').toPandas().drop(columns=['number_of_near_miss_incidents'])\n",
    "\n",
    "# Create training and test datasets\n",
    "label = 'is_near_miss'\n",
    "keys = ['production_date']\n",
    "X = ml_df_class.drop(columns=[label]+keys)\n",
    "y = ml_df_class[label]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)\n",
    "\n",
    "# Use standard scaling\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "# Solve class imbalance using SMOTE\n",
    "# logger.info(f'Class distribution before SMOTE: {Counter(y_train)}')\n",
    "# sm = SMOTE(random_state=42)\n",
    "# X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "# logger.info(f'Class distribution after SMOTE: {Counter(y_train)}')\n",
    "\n",
    "# Prepare the datasets for Autogluon\n",
    "train_data = pd.DataFrame(X_train, columns=X.columns)\n",
    "train_data[label] = y_train.values\n",
    "\n",
    "test_data = pd.DataFrame(X_test, columns=X.columns)\n",
    "test_data[label] = y_test.values\n",
    "\n",
    "train_data_auto = TabularDataset(train_data)\n",
    "test_data_auto = TabularDataset(test_data)\n",
    "\n",
    "logger.info(f\"Train data shape: {train_data_auto.shape}\")\n",
    "logger.info(f\"Test data shape: {test_data_auto.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee5bf665-7593-4520-88b5-3eda96cb976b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# label = 'is_near_miss'\n",
    "# train_data_auto = spark.table('hive_metastore.groupdb_rakona.hse_cc_inc_pred_ml_train').toPandas()\n",
    "# test_data_auto = spark.table('hive_metastore.groupdb_rakona.hse_cc_inc_pred_ml_test').toPandas()\n",
    "\n",
    "# print(f\"Train data shape: {train_data_auto.shape}\")\n",
    "# print(f\"Test data shape: {test_data_auto.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a6c93fa-0f8f-483b-a770-7e40d0fc5079",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250623_060512-001\"\nVerbosity: 2 (Standard Logging)\n=================== System Info ===================\nAutoGluon Version:  1.3.1\nPython Version:     3.12.3\nOperating System:   Linux\nPlatform Machine:   x86_64\nPlatform Version:   #33~22.04.1-Ubuntu SMP Fri Apr 25 06:39:10 UTC 2025\nCPU Count:          8\nMemory Avail:       39.85 GB / 57.39 GB (69.4%)\nDisk Space Avail:   10.00 GB / 10.00 GB (100.0%)\n\tWARNING: Available disk space is low and there is a risk that AutoGluon will run out of disk during fit, causing an exception. \n\tWe recommend a minimum available disk space of 10 GB, and large datasets may require more.\n===================================================\nPresets specified: ['best_quality']\nSetting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\nStack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\nDyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n2025-06-23 06:05:14,586\tINFO worker.py:1810 -- Started a local Ray instance. View the dashboard at \u001B[1m\u001B[32mhttp://127.0.0.1:8266 \u001B[39m\u001B[22m\n\t\tContext path: \"/Workspace/Users/mubeen.am@pg.com/Port Qasim HSE Command Center V2/AutogluonModels/ag-20250623_060512-001/ds_sub_fit/sub_fit_ho\"\n\u001B[36m(_dystack pid=6051)\u001B[0m Running DyStack sub-fit ...\n\u001B[36m(_dystack pid=6051)\u001B[0m Beginning AutoGluon training ... Time limit = 897s\n\u001B[36m(_dystack pid=6051)\u001B[0m AutoGluon will save models to \"/Workspace/Users/mubeen.am@pg.com/Port Qasim HSE Command Center V2/AutogluonModels/ag-20250623_060512-001/ds_sub_fit/sub_fit_ho\"\n\u001B[36m(_dystack pid=6051)\u001B[0m Train Data Rows:    3510\n\u001B[36m(_dystack pid=6051)\u001B[0m Train Data Columns: 25\n\u001B[36m(_dystack pid=6051)\u001B[0m Label Column:       is_near_miss\n\u001B[36m(_dystack pid=6051)\u001B[0m Problem Type:       binary\n\u001B[36m(_dystack pid=6051)\u001B[0m Preprocessing data ...\n\u001B[36m(_dystack pid=6051)\u001B[0m Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n\u001B[36m(_dystack pid=6051)\u001B[0m Using Feature Generators to preprocess the data ...\n\u001B[36m(_dystack pid=6051)\u001B[0m Fitting AutoMLPipelineFeatureGenerator...\n\u001B[36m(_dystack pid=6051)\u001B[0m \tAvailable Memory:                    39833.86 MB\n\u001B[36m(_dystack pid=6051)\u001B[0m \tTrain Data (Original)  Memory Usage: 1.03 MB (0.0% of available memory)\n\u001B[36m(_dystack pid=6051)\u001B[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n\u001B[36m(_dystack pid=6051)\u001B[0m \tStage 1 Generators:\n\u001B[36m(_dystack pid=6051)\u001B[0m \t\tFitting AsTypeFeatureGenerator...\n\u001B[36m(_dystack pid=6051)\u001B[0m \t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n\u001B[36m(_dystack pid=6051)\u001B[0m \tStage 2 Generators:\n\u001B[36m(_dystack pid=6051)\u001B[0m \t\tFitting FillNaFeatureGenerator...\n\u001B[36m(_dystack pid=6051)\u001B[0m \tStage 3 Generators:\n\u001B[36m(_dystack pid=6051)\u001B[0m \t\tFitting IdentityFeatureGenerator...\n\u001B[36m(_dystack pid=6051)\u001B[0m \t\tFitting CategoryFeatureGenerator...\n\u001B[36m(_dystack pid=6051)\u001B[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n\u001B[36m(_dystack pid=6051)\u001B[0m \tStage 4 Generators:\n\u001B[36m(_dystack pid=6051)\u001B[0m \t\tFitting DropUniqueFeatureGenerator...\n\u001B[36m(_dystack pid=6051)\u001B[0m \tStage 5 Generators:\n\u001B[36m(_dystack pid=6051)\u001B[0m \t\tFitting DropDuplicatesFeatureGenerator...\n\u001B[36m(_dystack pid=6051)\u001B[0m \tUseless Original Features (Count: 1): ['breakdowns']\n\u001B[36m(_dystack pid=6051)\u001B[0m \t\tThese features carry no predictive signal and should be manually investigated.\n\u001B[36m(_dystack pid=6051)\u001B[0m \t\tThis is typically a feature which has the same value for all rows.\n\u001B[36m(_dystack pid=6051)\u001B[0m \t\tThese features do not need to be present at inference time.\n\u001B[36m(_dystack pid=6051)\u001B[0m \tTypes of features in original data (raw dtype, special dtypes):\n\u001B[36m(_dystack pid=6051)\u001B[0m \t\t('float', [])  : 22 | ['constrained_stops', 'planned_count', 'unplanned_count', 'duration_sum', 'constrained_stops_per_day', ...]\n\u001B[36m(_dystack pid=6051)\u001B[0m \t\t('object', []) :  2 | ['department_name', 'line_name']\n\u001B[36m(_dystack pid=6051)\u001B[0m \tTypes of features in processed data (raw dtype, special dtypes):\n\u001B[36m(_dystack pid=6051)\u001B[0m \t\t('category', [])  :  2 | ['department_name', 'line_name']\n\u001B[36m(_dystack pid=6051)\u001B[0m \t\t('float', [])     : 21 | ['constrained_stops', 'planned_count', 'unplanned_count', 'duration_sum', 'constrained_stops_per_day', ...]\n\u001B[36m(_dystack pid=6051)\u001B[0m \t\t('int', ['bool']) :  1 | ['compliance_perc']\n\u001B[36m(_dystack pid=6051)\u001B[0m \t0.0s = Fit runtime\n\u001B[36m(_dystack pid=6051)\u001B[0m \t24 features in original data used to generate 24 features in processed data.\n\u001B[36m(_dystack pid=6051)\u001B[0m \tTrain Data (Processed) Memory Usage: 0.57 MB (0.0% of available memory)\n\u001B[36m(_dystack pid=6051)\u001B[0m Data preprocessing and feature engineering runtime = 0.04s ...\n\u001B[36m(_dystack pid=6051)\u001B[0m AutoGluon will gauge predictive performance using evaluation metric: 'f1'\n\u001B[36m(_dystack pid=6051)\u001B[0m \tTo change this, specify the eval_metric parameter of Predictor()\n\u001B[36m(_dystack pid=6051)\u001B[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n\u001B[36m(_dystack pid=6051)\u001B[0m User-specified model hyperparameters to be fit:\n\u001B[36m(_dystack pid=6051)\u001B[0m {\n\u001B[36m(_dystack pid=6051)\u001B[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n\u001B[36m(_dystack pid=6051)\u001B[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n\u001B[36m(_dystack pid=6051)\u001B[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n\u001B[36m(_dystack pid=6051)\u001B[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n\u001B[36m(_dystack pid=6051)\u001B[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n\u001B[36m(_dystack pid=6051)\u001B[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n\u001B[36m(_dystack pid=6051)\u001B[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n\u001B[36m(_dystack pid=6051)\u001B[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n\u001B[36m(_dystack pid=6051)\u001B[0m }\n\u001B[36m(_dystack pid=6051)\u001B[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n\u001B[36m(_dystack pid=6051)\u001B[0m Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n\u001B[36m(_dystack pid=6051)\u001B[0m Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 598.01s of the 897.23s of remaining time.\n\u001B[36m(_dystack pid=6051)\u001B[0m \t0.0\t = Validation score   (f1)\n\u001B[36m(_dystack pid=6051)\u001B[0m \t0.01s\t = Training   runtime\n\u001B[36m(_dystack pid=6051)\u001B[0m \t0.06s\t = Validation runtime\n\u001B[36m(_dystack pid=6051)\u001B[0m Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 595.96s of the 895.19s of remaining time.\n\u001B[36m(_dystack pid=6051)\u001B[0m \t0.0253\t = Validation score   (f1)\n\u001B[36m(_dystack pid=6051)\u001B[0m \t0.0s\t = Training   runtime\n\u001B[36m(_dystack pid=6051)\u001B[0m \t0.02s\t = Validation runtime\n\u001B[36m(_dystack pid=6051)\u001B[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 595.17s of the 894.40s of remaining time.\n\u001B[36m(_dystack pid=6051)\u001B[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n\u001B[36m(_dystack pid=6051)\u001B[0m \t0.0882\t = Validation score   (f1)\n\u001B[36m(_dystack pid=6051)\u001B[0m \t3.77s\t = Training   runtime\n\u001B[36m(_dystack pid=6051)\u001B[0m \t0.04s\t = Validation runtime\n\u001B[36m(_dystack pid=6051)\u001B[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 584.03s of the 883.25s of remaining time.\n\u001B[36m(_dystack pid=6051)\u001B[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n\u001B[36m(_dystack pid=6051)\u001B[0m \t0.0323\t = Validation score   (f1)\n\u001B[36m(_dystack pid=6051)\u001B[0m \t1.26s\t = Training   runtime\n\u001B[36m(_dystack pid=6051)\u001B[0m \t0.02s\t = Validation runtime\n\u001B[36m(_dystack pid=6051)\u001B[0m Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 579.28s of the 878.50s of remaining time.\n\u001B[36m(_dystack pid=6051)\u001B[0m \t0.0506\t = Validation score   (f1)\n\u001B[36m(_dystack pid=6051)\u001B[0m \t0.48s\t = Training   runtime\n\u001B[36m(_dystack pid=6051)\u001B[0m \t0.09s\t = Validation runtime\n\u001B[36m(_dystack pid=6051)\u001B[0m Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 574.78s of the 874.00s of remaining time.\n\u001B[36m(_dystack pid=6051)\u001B[0m \t0.026\t = Validation score   (f1)\n\u001B[36m(_dystack pid=6051)\u001B[0m \t0.68s\t = Training   runtime\n\u001B[36m(_dystack pid=6051)\u001B[0m \t0.1s\t = Validation runtime\n\u001B[36m(_dystack pid=6051)\u001B[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 572.63s of the 871.85s of remaining time.\n\u001B[36m(_dystack pid=6051)\u001B[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.05%)\n\u001B[36m(_dystack pid=6051)\u001B[0m \t0.0\t = Validation score   (f1)\n\u001B[36m(_dystack pid=6051)\u001B[0m \t3.7s\t = Training   runtime\n\u001B[36m(_dystack pid=6051)\u001B[0m \t0.02s\t = Validation runtime\n\u001B[36m(_dystack pid=6051)\u001B[0m Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 566.24s of the 865.46s of remaining time.\n\u001B[36m(_dystack pid=6051)\u001B[0m \t0.0723\t = Validation score   (f1)\n\u001B[36m(_dystack pid=6051)\u001B[0m \t0.52s\t = Training   runtime\n\u001B[36m(_dystack pid=6051)\u001B[0m \t0.11s\t = Validation runtime\n\u001B[36m(_dystack pid=6051)\u001B[0m Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 563.59s of the 862.81s of remaining time.\n\u001B[36m(_dystack pid=6051)\u001B[0m \t0.0506\t = Validation score   (f1)\n\u001B[36m(_dystack pid=6051)\u001B[0m \t0.89s\t = Training   runtime\n\u001B[36m(_dystack pid=6051)\u001B[0m \t0.2s\t = Validation runtime\n\u001B[36m(_dystack pid=6051)\u001B[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 558.80s of the 858.03s of remaining time.\n\u001B[36m(_dystack pid=6051)\u001B[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n\u001B[36m(_ray_fit pid=9484)\u001B[0m No improvement since epoch 0: early stopping\n\u001B[36m(_dystack pid=6051)\u001B[0m \t0.1921\t = Validation score   (f1)\n\u001B[36m(_dystack pid=6051)\u001B[0m \t8.07s\t = Training   runtime\n\u001B[36m(_dystack pid=6051)\u001B[0m \t0.09s\t = Validation runtime\n\u001B[36m(_dystack pid=6051)\u001B[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 545.59s of the 844.81s of remaining time.\n\u001B[36m(_dystack pid=6051)\u001B[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.05%)\n\u001B[36m(_dystack pid=6051)\u001B[0m \t0.0909\t = Validation score   (f1)\n\u001B[36m(_dystack pid=6051)\u001B[0m \t2.48s\t = Training   runtime\n\u001B[36m(_dystack pid=6051)\u001B[0m \t0.07s\t = Validation runtime\n\u001B[36m(_ray_fit pid=9489)\u001B[0m No improvement since epoch 6: early stopping\u001B[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001B[0m\n\u001B[36m(_dystack pid=6051)\u001B[0m Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 539.44s of the 838.66s of remaining time.\n\u001B[36m(_dystack pid=6051)\u001B[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n\u001B[36m(_dystack pid=6051)\u001B[0m \tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n\u001B[36m(_dystack pid=6051)\u001B[0m \t\t\u001B[36mray::_ray_fit()\u001B[39m (pid=10774, ip=10.99.12.6)\n\u001B[36m(_dystack pid=6051)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n\u001B[36m(_dystack pid=6051)\u001B[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n\u001B[36m(_dystack pid=6051)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n\u001B[36m(_dystack pid=6051)\u001B[0m     out = self._fit(**kwargs)\n\u001B[36m(_dystack pid=6051)\u001B[0m           ^^^^^^^^^^^^^^^^^^^\n\u001B[36m(_dystack pid=6051)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n\u001B[36m(_dystack pid=6051)\u001B[0m     train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n\u001B[36m(_dystack pid=6051)\u001B[0m                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001B[36m(_dystack pid=6051)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n\u001B[36m(_dystack pid=6051)\u001B[0m     dataset = self._process_train_data(\n\u001B[36m(_dystack pid=6051)\u001B[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001B[36m(_dystack pid=6051)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n\u001B[36m(_dystack pid=6051)\u001B[0m     self.processor = create_preprocessor(\n\u001B[36m(_dystack pid=6051)\u001B[0m                      ^^^^^^^^^^^^^^^^^^^^\n\u001B[36m(_dystack pid=6051)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n\u001B[36m(_dystack pid=6051)\u001B[0m     return ColumnTransformer(\n\u001B[36m(_dystack pid=6051)\u001B[0m            ^^^^^^^^^^^^^^^^^^\n\u001B[36m(_dystack pid=6051)\u001B[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n\u001B[36m(_dystack pid=6051)\u001B[0m Detailed Traceback:\n\u001B[36m(_dystack pid=6051)\u001B[0m Traceback (most recent call last):\n\u001B[36m(_dystack pid=6051)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2169, in _train_and_save\n\u001B[36m(_dystack pid=6051)\u001B[0m     model = self._train_single(**model_fit_kwargs)\n\u001B[36m(_dystack pid=6051)\u001B[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001B[36m(_dystack pid=6051)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2055, in _train_single\n\u001B[36m(_dystack pid=6051)\u001B[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n\u001B[36m(_dystack pid=6051)\u001B[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001B[36m(_dystack pid=6051)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n\u001B[36m(_dystack pid=6051)\u001B[0m     out = self._fit(**kwargs)\n\u001B[36m(_dystack pid=6051)\u001B[0m           ^^^^^^^^^^^^^^^^^^^\n\u001B[36m(_dystack pid=6051)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n\u001B[36m(_dystack pid=6051)\u001B[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n\u001B[36m(_dystack pid=6051)\u001B[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001B[36m(_dystack pid=6051)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n\u001B[36m(_dystack pid=6051)\u001B[0m     self._fit_folds(\n\u001B[36m(_dystack pid=6051)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n\u001B[36m(_dystack pid=6051)\u001B[0m     fold_fitting_strategy.after_all_folds_scheduled()\n\u001B[36m(_dystack pid=6051)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n\u001B[36m(_dystack pid=6051)\u001B[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n\u001B[36m(_dystack pid=6051)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n\u001B[36m(_dystack pid=6051)\u001B[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n\u001B[36m(_dystack pid=6051)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n\u001B[36m(_dystack pid=6051)\u001B[0m     raise processed_exception\n\u001B[36m(_dystack pid=6051)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n\u001B[36m(_dystack pid=6051)\u001B[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n\u001B[36m(_dystack pid=6051)\u001B[0m                                                                                                                                      ^^^^^^^^^^^^^^^^^^^^^^\n\u001B[36m(_dystack pid=6051)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n\u001B[36m(_dystack pid=6051)\u001B[0m     return fn(*args, **kwargs)\n\u001B[36m(_dystack pid=6051)\u001B[0m            ^^^^^^^^^^^^^^^^^^^\n\u001B[36m(_dystack pid=6051)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n\u001B[36m(_dystack pid=6051)\u001B[0m     return func(*args, **kwargs)\n\u001B[36m(_dystack pid=6051)\u001B[0m            ^^^^^^^^^^^^^^^^^^^^^\n\u001B[36m(_dystack pid=6051)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/ray/_private/worker.py\", line 2753, in get\n\u001B[36m(_dystack pid=6051)\u001B[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n\u001B[36m(_dystack pid=6051)\u001B[0m                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001B[36m(_dystack pid=6051)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/ray/_private/worker.py\", line 904, in get_objects\n\u001B[36m(_dystack pid=6051)\u001B[0m     raise value.as_instanceof_cause()\n\u001B[36m(_dystack pid=6051)\u001B[0m ray.exceptions.RayTaskError(TypeError): \u001B[36mray::_ray_fit()\u001B[39m (pid=10774, ip=10.99.12.6)\n\u001B[36m(_dystack pid=6051)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n\u001B[36m(_dystack pid=6051)\u001B[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n\u001B[36m(_dystack pid=6051)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n\u001B[36m(_dystack pid=6051)\u001B[0m     out = self._fit(**kwargs)\n\u001B[36m(_dystack pid=6051)\u001B[0m           ^^^^^^^^^^^^^^^^^^^\n\u001B[36m(_dystack pid=6051)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n\u001B[36m(_dystack pid=6051)\u001B[0m     train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n\u001B[36m(_dystack pid=6051)\u001B[0m                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001B[36m(_dystack pid=6051)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n\u001B[36m(_dystack pid=6051)\u001B[0m     dataset = self._process_train_data(\n\u001B[36m(_dystack pid=6051)\u001B[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001B[36m(_dystack pid=6051)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n\u001B[36m(_dystack pid=6051)\u001B[0m     self.processor = create_preprocessor(\n\u001B[36m(_dystack pid=6051)\u001B[0m                      ^^^^^^^^^^^^^^^^^^^^\n\u001B[36m(_dystack pid=6051)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n\u001B[36m(_dystack pid=6051)\u001B[0m     return ColumnTransformer(\n\u001B[36m(_dystack pid=6051)\u001B[0m            ^^^^^^^^^^^^^^^^^^\n\u001B[36m(_dystack pid=6051)\u001B[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n\u001B[36m(_dystack pid=6051)\u001B[0m Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 530.72s of the 829.94s of remaining time.\n\u001B[36m(_dystack pid=6051)\u001B[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 wo\n\n*** WARNING: max output size exceeded, skipping output. ***\n\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n    dataset = self._process_train_data(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n    self.processor = create_preprocessor(\n                     ^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n    return ColumnTransformer(\n           ^^^^^^^^^^^^^^^^^^\nTypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\nFitting model: XGBoost_r95_BAG_L2 ... Training model for up to 119.03s of the 117.93s of remaining time.\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.18%)\n2025-06-23 07:03:22,235\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n2025-06-23 07:03:22,237\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n2025-06-23 07:03:22,238\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n2025-06-23 07:03:22,239\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n2025-06-23 07:03:22,240\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n2025-06-23 07:03:22,240\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n2025-06-23 07:03:22,242\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n\t0.1333\t = Validation score   (f1)\n\t3.42s\t = Training   runtime\n\t0.09s\t = Validation runtime\nFitting model: XGBoost_r34_BAG_L2 ... Training model for up to 109.06s of the 107.96s of remaining time.\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.03%)\n\t0.0833\t = Validation score   (f1)\n\t2.84s\t = Training   runtime\n\t0.05s\t = Validation runtime\nFitting model: LightGBM_r42_BAG_L2 ... Training model for up to 101.34s of the 100.24s of remaining time.\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.44%)\n\t0.1067\t = Validation score   (f1)\n\t3.85s\t = Training   runtime\n\t0.09s\t = Validation runtime\nFitting model: NeuralNetTorch_r1_BAG_L2 ... Training model for up to 91.87s of the 90.77s of remaining time.\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n\tWarning: Exception caused NeuralNetTorch_r1_BAG_L2 to fail during training... Skipping this model.\n\t\t\u001B[36mray::_ray_fit()\u001B[39m (pid=183665, ip=10.99.12.6)\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n    out = self._fit(**kwargs)\n          ^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n    train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n    dataset = self._process_train_data(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n    self.processor = create_preprocessor(\n                     ^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n    return ColumnTransformer(\n           ^^^^^^^^^^^^^^^^^^\nTypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\nDetailed Traceback:\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2169, in _train_and_save\n    model = self._train_single(**model_fit_kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2055, in _train_single\n    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n    out = self._fit(**kwargs)\n          ^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n    self._fit_folds(\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n    fold_fitting_strategy.after_all_folds_scheduled()\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n    self._process_fold_results(finished, unfinished, fold_ctx)\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n    raise processed_exception\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n                                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/ray/_private/worker.py\", line 2753, in get\n    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/ray/_private/worker.py\", line 904, in get_objects\n    raise value.as_instanceof_cause()\nray.exceptions.RayTaskError(TypeError): \u001B[36mray::_ray_fit()\u001B[39m (pid=183665, ip=10.99.12.6)\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n    out = self._fit(**kwargs)\n          ^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n    train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n    dataset = self._process_train_data(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n    self.processor = create_preprocessor(\n                     ^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n    return ColumnTransformer(\n           ^^^^^^^^^^^^^^^^^^\nTypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\nFitting model: NeuralNetTorch_r89_BAG_L2 ... Training model for up to 83.24s of the 82.14s of remaining time.\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n2025-06-23 07:03:57,251\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n2025-06-23 07:03:57,252\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n2025-06-23 07:03:57,253\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n2025-06-23 07:03:57,253\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n2025-06-23 07:03:57,254\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n2025-06-23 07:03:58,251\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n2025-06-23 07:03:58,253\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n\tWarning: Exception caused NeuralNetTorch_r89_BAG_L2 to fail during training... Skipping this model.\n\t\t\u001B[36mray::_ray_fit()\u001B[39m (pid=184025, ip=10.99.12.6)\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n    out = self._fit(**kwargs)\n          ^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n    train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n    dataset = self._process_train_data(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n    self.processor = create_preprocessor(\n                     ^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n    return ColumnTransformer(\n           ^^^^^^^^^^^^^^^^^^\nTypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\nDetailed Traceback:\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2169, in _train_and_save\n    model = self._train_single(**model_fit_kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2055, in _train_single\n    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n    out = self._fit(**kwargs)\n          ^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n    self._fit_folds(\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n    fold_fitting_strategy.after_all_folds_scheduled()\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n    self._process_fold_results(finished, unfinished, fold_ctx)\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n    raise processed_exception\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n                                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/ray/_private/worker.py\", line 2753, in get\n    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/ray/_private/worker.py\", line 904, in get_objects\n    raise value.as_instanceof_cause()\nray.exceptions.RayTaskError(TypeError): \u001B[36mray::_ray_fit()\u001B[39m (pid=184025, ip=10.99.12.6)\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n    out = self._fit(**kwargs)\n          ^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n    train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n    dataset = self._process_train_data(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n    self.processor = create_preprocessor(\n                     ^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-266801f1-c994-49e4-a797-d681986b6d3b/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n    return ColumnTransformer(\n           ^^^^^^^^^^^^^^^^^^\nTypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n2025-06-23 07:04:07,254\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n2025-06-23 07:04:07,256\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n2025-06-23 07:04:07,260\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n2025-06-23 07:04:07,262\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n2025-06-23 07:04:07,263\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n2025-06-23 07:04:07,264\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n2025-06-23 07:04:07,265\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\nFitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 13.68s of remaining time.\n\tEnsemble Weights: {'NeuralNetFastAI_r194_BAG_L2': 0.8, 'NeuralNetFastAI_r138_BAG_L2': 0.133, 'KNeighborsUnif_BAG_L1': 0.067}\n\t0.314\t = Validation score   (f1)\n\t0.37s\t = Training   runtime\n\t0.0s\t = Validation runtime\nAutoGluon training complete, total runtime = 2242.49s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 486.7 rows/s (494 batch size)\nEnabling decision threshold calibration (calibrate_decision_threshold='auto', metric is valid, problem_type is 'binary')\nCalibrating decision threshold to optimize metric f1 | Checking 51 thresholds...\nCalibrating decision threshold via fine-grained search | Checking 38 thresholds...\n\tBase Threshold: 0.500\t| val: 0.3140\n\tBest Threshold: 0.500\t| val: 0.3140\nTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Workspace/Users/mubeen.am@pg.com/Port Qasim HSE Command Center V2/AutogluonModels/ag-20250623_060512-001\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=label, eval_metric=\"f1\").fit(\n",
    "    train_data_auto,\n",
    "    # time_limit=600,\n",
    "    presets=\"best_quality\"\n",
    "    # num_bag_folds=5,\n",
    "    # num_stack_levels=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8203c17-1925-462b-949f-ddcf38b5d415",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NeuralNetFastAI_r172_BAG_L1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.978736</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.209677</td>\n",
       "      <td>f1</td>\n",
       "      <td>2.225834</td>\n",
       "      <td>0.139336</td>\n",
       "      <td>10.170036</td>\n",
       "      <td>2.225834</td>\n",
       "      <td>0.139336</td>\n",
       "      <td>10.170036</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NeuralNetFastAI_r145_BAG_L2</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.979917</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>f1</td>\n",
       "      <td>19.754344</td>\n",
       "      <td>1.760209</td>\n",
       "      <td>61.883509</td>\n",
       "      <td>2.712040</td>\n",
       "      <td>0.452743</td>\n",
       "      <td>11.225957</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NeuralNetFastAI_r11_BAG_L1</td>\n",
       "      <td>0.218182</td>\n",
       "      <td>0.974601</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.196721</td>\n",
       "      <td>f1</td>\n",
       "      <td>2.910932</td>\n",
       "      <td>0.249604</td>\n",
       "      <td>25.303378</td>\n",
       "      <td>2.910932</td>\n",
       "      <td>0.249604</td>\n",
       "      <td>25.303378</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NeuralNetFastAI_r187_BAG_L2</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.978736</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>f1</td>\n",
       "      <td>19.010379</td>\n",
       "      <td>1.478873</td>\n",
       "      <td>60.331643</td>\n",
       "      <td>1.968075</td>\n",
       "      <td>0.171407</td>\n",
       "      <td>9.674091</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NeuralNetFastAI_r111_BAG_L2</td>\n",
       "      <td>0.212766</td>\n",
       "      <td>0.978145</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>f1</td>\n",
       "      <td>19.353971</td>\n",
       "      <td>1.403149</td>\n",
       "      <td>55.148122</td>\n",
       "      <td>2.311668</td>\n",
       "      <td>0.095683</td>\n",
       "      <td>4.490570</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>NeuralNetFastAI_r172_BAG_L2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.979917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.227545</td>\n",
       "      <td>f1</td>\n",
       "      <td>19.490495</td>\n",
       "      <td>1.384457</td>\n",
       "      <td>55.870710</td>\n",
       "      <td>2.448192</td>\n",
       "      <td>0.076990</td>\n",
       "      <td>5.213158</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>XGBoost_r49_BAG_L2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.982280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>f1</td>\n",
       "      <td>19.507250</td>\n",
       "      <td>1.368252</td>\n",
       "      <td>56.086085</td>\n",
       "      <td>2.464946</td>\n",
       "      <td>0.060785</td>\n",
       "      <td>5.428533</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>XGBoost_r31_BAG_L2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.982280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>f1</td>\n",
       "      <td>19.688185</td>\n",
       "      <td>1.348887</td>\n",
       "      <td>52.401503</td>\n",
       "      <td>2.645881</td>\n",
       "      <td>0.041421</td>\n",
       "      <td>1.743951</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>XGBoost_r98_BAG_L2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.982280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>f1</td>\n",
       "      <td>19.822461</td>\n",
       "      <td>1.409595</td>\n",
       "      <td>54.803627</td>\n",
       "      <td>2.780158</td>\n",
       "      <td>0.102129</td>\n",
       "      <td>4.146075</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>XGBoost_BAG_L2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.982280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>f1</td>\n",
       "      <td>19.951042</td>\n",
       "      <td>1.352269</td>\n",
       "      <td>52.426143</td>\n",
       "      <td>2.908739</td>\n",
       "      <td>0.044803</td>\n",
       "      <td>1.768591</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           model  score_test  ...  can_infer  fit_order\n",
       "0    NeuralNetFastAI_r172_BAG_L1    0.250000  ...       True         74\n",
       "1    NeuralNetFastAI_r145_BAG_L2    0.227273  ...       True        113\n",
       "2     NeuralNetFastAI_r11_BAG_L1    0.218182  ...       True         29\n",
       "3    NeuralNetFastAI_r187_BAG_L2    0.217391  ...       True        174\n",
       "4    NeuralNetFastAI_r111_BAG_L2    0.212766  ...       True        142\n",
       "..                           ...         ...  ...        ...        ...\n",
       "173  NeuralNetFastAI_r172_BAG_L2    0.000000  ...       True        162\n",
       "174           XGBoost_r49_BAG_L2    0.000000  ...       True        147\n",
       "175           XGBoost_r31_BAG_L2    0.000000  ...       True        152\n",
       "176           XGBoost_r98_BAG_L2    0.000000  ...       True        130\n",
       "177               XGBoost_BAG_L2    0.000000  ...       True         99\n",
       "\n",
       "[178 rows x 16 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data_auto, extra_metrics=['accuracy', 'precision', 'recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bfa0814-b535-4e4f-91d5-d3428c316407",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'f1': np.float64(0.25),\n",
       " 'accuracy': 0.9787359716479622,\n",
       " 'balanced_accuracy': np.float64(0.5963920625375827),\n",
       " 'mcc': np.float64(0.2479901107382674),\n",
       " 'roc_auc': np.float64(0.8358689116055321),\n",
       " 'precision': np.float64(0.3333333333333333),\n",
       " 'recall': np.float64(0.2)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(test_data_auto, model='NeuralNetFastAI_r172_BAG_L1', silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a06cfe24-a87a-4760-b451-c7c5a6034810",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "These features in provided data are not utilized by the predictor and will be ignored: ['breakdowns']\nComputing feature importance via permutation shuffling for 24 features using 1693 rows with 5 shuffle sets...\n\t159.9s\t= Expected runtime (31.98s per shuffle set)\n\t10.72s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>line_name</th>\n",
       "      <td>0.179412</td>\n",
       "      <td>0.064438</td>\n",
       "      <td>1.694764e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.312090</td>\n",
       "      <td>0.046733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_sum</th>\n",
       "      <td>0.148413</td>\n",
       "      <td>0.024896</td>\n",
       "      <td>9.155540e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.199674</td>\n",
       "      <td>0.097152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_defects</th>\n",
       "      <td>0.117826</td>\n",
       "      <td>0.001588</td>\n",
       "      <td>3.954362e-09</td>\n",
       "      <td>5</td>\n",
       "      <td>0.121095</td>\n",
       "      <td>0.114557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unplanned_stops_per_day</th>\n",
       "      <td>0.113961</td>\n",
       "      <td>0.017270</td>\n",
       "      <td>6.138978e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.149519</td>\n",
       "      <td>0.078403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unplanned_count</th>\n",
       "      <td>0.102584</td>\n",
       "      <td>0.019537</td>\n",
       "      <td>1.505244e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.142812</td>\n",
       "      <td>0.062357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>department_name</th>\n",
       "      <td>0.060713</td>\n",
       "      <td>0.031597</td>\n",
       "      <td>6.339937e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.125771</td>\n",
       "      <td>-0.004345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_defects_yesterday</th>\n",
       "      <td>0.059966</td>\n",
       "      <td>0.036252</td>\n",
       "      <td>1.042859e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>0.134609</td>\n",
       "      <td>-0.014677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_resolved_in_24_hours</th>\n",
       "      <td>0.054402</td>\n",
       "      <td>0.021600</td>\n",
       "      <td>2.445619e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.098877</td>\n",
       "      <td>0.009926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>completed_perc</th>\n",
       "      <td>0.052102</td>\n",
       "      <td>0.030706</td>\n",
       "      <td>9.599478e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.115325</td>\n",
       "      <td>-0.011121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>safe_percentage</th>\n",
       "      <td>0.047664</td>\n",
       "      <td>0.033529</td>\n",
       "      <td>1.678762e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>0.116701</td>\n",
       "      <td>-0.021372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>constrained_stops</th>\n",
       "      <td>0.044658</td>\n",
       "      <td>0.024735</td>\n",
       "      <td>7.820926e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.095589</td>\n",
       "      <td>-0.006272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compliance_perc</th>\n",
       "      <td>0.038484</td>\n",
       "      <td>0.035381</td>\n",
       "      <td>3.590645e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>0.111334</td>\n",
       "      <td>-0.034366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unsafe_percentage</th>\n",
       "      <td>0.033794</td>\n",
       "      <td>0.019694</td>\n",
       "      <td>9.252442e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.074344</td>\n",
       "      <td>-0.006755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per_unresolved_in_7_days</th>\n",
       "      <td>0.027896</td>\n",
       "      <td>0.016123</td>\n",
       "      <td>9.005525e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.061093</td>\n",
       "      <td>-0.005301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_positive_feedbacks</th>\n",
       "      <td>0.025283</td>\n",
       "      <td>0.031886</td>\n",
       "      <td>7.545354e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>0.090937</td>\n",
       "      <td>-0.040371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>completed_audits</th>\n",
       "      <td>0.023103</td>\n",
       "      <td>0.013940</td>\n",
       "      <td>1.036354e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>0.051806</td>\n",
       "      <td>-0.005599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_unresolved_in_30_days</th>\n",
       "      <td>0.012041</td>\n",
       "      <td>0.021373</td>\n",
       "      <td>1.381259e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.056047</td>\n",
       "      <td>-0.031966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>planned_stops_per_day</th>\n",
       "      <td>0.011939</td>\n",
       "      <td>0.019194</td>\n",
       "      <td>1.183271e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.051459</td>\n",
       "      <td>-0.027582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>planned_count</th>\n",
       "      <td>0.011939</td>\n",
       "      <td>0.019194</td>\n",
       "      <td>1.183271e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.051459</td>\n",
       "      <td>-0.027582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>constrained_stops_per_day</th>\n",
       "      <td>0.011939</td>\n",
       "      <td>0.019194</td>\n",
       "      <td>1.183271e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.051459</td>\n",
       "      <td>-0.027582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_unresolved_in_7_days</th>\n",
       "      <td>0.001913</td>\n",
       "      <td>0.006898</td>\n",
       "      <td>2.843733e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.016117</td>\n",
       "      <td>-0.012291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per_unresolved_in_30_days</th>\n",
       "      <td>-0.002174</td>\n",
       "      <td>0.004861</td>\n",
       "      <td>8.130495e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.007835</td>\n",
       "      <td>-0.012183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_corrective_feedbacks</th>\n",
       "      <td>-0.005319</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.005319</td>\n",
       "      <td>-0.005319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per_resolved_in_24_hours</th>\n",
       "      <td>-0.023425</td>\n",
       "      <td>0.026848</td>\n",
       "      <td>9.385879e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.031856</td>\n",
       "      <td>-0.078706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            importance    stddev  ...  p99_high   p99_low\n",
       "line_name                     0.179412  0.064438  ...  0.312090  0.046733\n",
       "duration_sum                  0.148413  0.024896  ...  0.199674  0.097152\n",
       "total_defects                 0.117826  0.001588  ...  0.121095  0.114557\n",
       "unplanned_stops_per_day       0.113961  0.017270  ...  0.149519  0.078403\n",
       "unplanned_count               0.102584  0.019537  ...  0.142812  0.062357\n",
       "department_name               0.060713  0.031597  ...  0.125771 -0.004345\n",
       "total_defects_yesterday       0.059966  0.036252  ...  0.134609 -0.014677\n",
       "num_resolved_in_24_hours      0.054402  0.021600  ...  0.098877  0.009926\n",
       "completed_perc                0.052102  0.030706  ...  0.115325 -0.011121\n",
       "safe_percentage               0.047664  0.033529  ...  0.116701 -0.021372\n",
       "constrained_stops             0.044658  0.024735  ...  0.095589 -0.006272\n",
       "compliance_perc               0.038484  0.035381  ...  0.111334 -0.034366\n",
       "unsafe_percentage             0.033794  0.019694  ...  0.074344 -0.006755\n",
       "per_unresolved_in_7_days      0.027896  0.016123  ...  0.061093 -0.005301\n",
       "no_of_positive_feedbacks      0.025283  0.031886  ...  0.090937 -0.040371\n",
       "completed_audits              0.023103  0.013940  ...  0.051806 -0.005599\n",
       "num_unresolved_in_30_days     0.012041  0.021373  ...  0.056047 -0.031966\n",
       "planned_stops_per_day         0.011939  0.019194  ...  0.051459 -0.027582\n",
       "planned_count                 0.011939  0.019194  ...  0.051459 -0.027582\n",
       "constrained_stops_per_day     0.011939  0.019194  ...  0.051459 -0.027582\n",
       "num_unresolved_in_7_days      0.001913  0.006898  ...  0.016117 -0.012291\n",
       "per_unresolved_in_30_days    -0.002174  0.004861  ...  0.007835 -0.012183\n",
       "no_of_corrective_feedbacks   -0.005319  0.000000  ... -0.005319 -0.005319\n",
       "per_resolved_in_24_hours     -0.023425  0.026848  ...  0.031856 -0.078706\n",
       "\n",
       "[24 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.feature_importance(test_data_auto, model='NeuralNetFastAI_r172_BAG_L1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54f6a076-4dc3-4ca2-8e33-2c738bd814b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02(2)-PQ-incidents-ml-class-automl-Jun-25",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}