{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4152163f-e073-461b-b2f3-091f8ebf6b7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# ML Experiment 1 - HSE CC PQ Incidents Prediction (June '25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e06b4b1-581e-4680-91b8-ce6eb0a649b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0e322c3-0774-4e25-8f5f-e2b8e73b9df8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.3\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e4bf303-4f76-4e44-a14e-d3e0d92e1b3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (24.0)\r\nCollecting pip\r\n  Using cached pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\r\nUsing cached pip-25.1.1-py3-none-any.whl (1.8 MB)\r\nInstalling collected packages: pip\r\n  Attempting uninstall: pip\r\n    Found existing installation: pip 24.0\r\n    Uninstalling pip-24.0:\r\n      Successfully uninstalled pip-24.0\r\nSuccessfully installed pip-25.1.1\r\n\u001B[33mDEPRECATION: Using the pkg_resources metadata backend is deprecated. pip 26.3 will enforce this behaviour change. A possible replacement is to use the default importlib.metadata backend, by unsetting the _PIP_USE_IMPORTLIB_METADATA environment variable. Discussion can be found at https://github.com/pypa/pip/issues/13317\u001B[0m\u001B[33m\r\n\u001B[0mCollecting autogluon\r\n  Using cached autogluon-1.3.1-py3-none-any.whl.metadata (11 kB)\r\nCollecting imbalanced-learn\r\n  Using cached imbalanced_learn-0.13.0-py3-none-any.whl.metadata (8.8 kB)\r\nCollecting loguru\r\n  Using cached loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\r\nCollecting autogluon.core==1.3.1 (from autogluon.core[all]==1.3.1->autogluon)\r\n  Using cached autogluon.core-1.3.1-py3-none-any.whl.metadata (12 kB)\r\nCollecting autogluon.features==1.3.1 (from autogluon)\r\n  Using cached autogluon.features-1.3.1-py3-none-any.whl.metadata (11 kB)\r\nCollecting autogluon.tabular==1.3.1 (from autogluon.tabular[all]==1.3.1->autogluon)\r\n  Using cached autogluon.tabular-1.3.1-py3-none-any.whl.metadata (14 kB)\r\nCollecting autogluon.multimodal==1.3.1 (from autogluon)\r\n  Using cached autogluon.multimodal-1.3.1-py3-none-any.whl.metadata (13 kB)\r\nCollecting autogluon.timeseries==1.3.1 (from autogluon.timeseries[all]==1.3.1->autogluon)\r\n  Using cached autogluon.timeseries-1.3.1-py3-none-any.whl.metadata (12 kB)\r\nRequirement already satisfied: numpy<2.3.0,>=1.25.0 in /databricks/python3/lib/python3.12/site-packages (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (1.26.4)\r\nRequirement already satisfied: scipy<1.16,>=1.5.4 in /databricks/python3/lib/python3.12/site-packages (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (1.13.1)\r\nRequirement already satisfied: scikit-learn<1.7.0,>=1.4.0 in /databricks/python3/lib/python3.12/site-packages (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (1.4.2)\r\nCollecting networkx<4,>=3.0 (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon)\r\n  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\r\nCollecting pandas<2.3.0,>=2.0.0 (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon)\r\n  Using cached pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\r\nCollecting tqdm<5,>=4.38 (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon)\r\n  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\r\nRequirement already satisfied: requests in /databricks/python3/lib/python3.12/site-packages (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (2.32.2)\r\nRequirement already satisfied: matplotlib<3.11,>=3.7.0 in /databricks/python3/lib/python3.12/site-packages (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (3.8.4)\r\nRequirement already satisfied: boto3<2,>=1.10 in /databricks/python3/lib/python3.12/site-packages (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (1.34.69)\r\nCollecting autogluon.common==1.3.1 (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon)\r\n  Using cached autogluon.common-1.3.1-py3-none-any.whl.metadata (11 kB)\r\nRequirement already satisfied: psutil<7.1.0,>=5.7.3 in /databricks/python3/lib/python3.12/site-packages (from autogluon.common==1.3.1->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (5.9.0)\r\nCollecting ray<2.45,>=2.10.0 (from ray[default]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\r\n  Using cached ray-2.44.1-cp312-cp312-manylinux2014_x86_64.whl.metadata (19 kB)\r\nCollecting hyperopt<0.2.8,>=0.2.7 (from autogluon.core[all]==1.3.1->autogluon)\r\n  Using cached hyperopt-0.2.7-py2.py3-none-any.whl.metadata (1.7 kB)\r\nRequirement already satisfied: pyarrow>=15.0.0 in /databricks/python3/lib/python3.12/site-packages (from autogluon.core[all]==1.3.1->autogluon) (15.0.2)\r\nRequirement already satisfied: Pillow<12,>=10.0.1 in /databricks/python3/lib/python3.12/site-packages (from autogluon.multimodal==1.3.1->autogluon) (10.3.0)\r\nCollecting torch<2.7,>=2.2 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Using cached torch-2.6.0-cp312-cp312-manylinux1_x86_64.whl.metadata (28 kB)\r\nCollecting lightning<2.7,>=2.2 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Using cached lightning-2.5.2-py3-none-any.whl.metadata (38 kB)\r\nCollecting transformers<4.50,>=4.38.0 (from transformers[sentencepiece]<4.50,>=4.38.0->autogluon.multimodal==1.3.1->autogluon)\r\n  Using cached transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\r\nCollecting accelerate<2.0,>=0.34.0 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Using cached accelerate-1.8.1-py3-none-any.whl.metadata (19 kB)\r\nCollecting jsonschema<4.24,>=4.18 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Using cached jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\r\nCollecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Using cached seqeval-1.2.2.tar.gz (43 kB)\r\n  Preparing metadata (setup.py) ... \u001B[?25l-\b \b\\\b \b|\b \bdone\r\n\u001B[?25hCollecting evaluate<0.5.0,>=0.4.0 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Using cached evaluate-0.4.4-py3-none-any.whl.metadata (9.5 kB)\r\nCollecting timm<1.0.7,>=0.9.5 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Using cached timm-1.0.3-py3-none-any.whl.metadata (43 kB)\r\nCollecting torchvision<0.22.0,>=0.16.0 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Using cached torchvision-0.21.0-cp312-cp312-manylinux1_x86_64.whl.metadata (6.1 kB)\r\nCollecting scikit-image<0.26.0,>=0.19.1 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Using cached scikit_image-0.25.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\r\nCollecting text-unidecode<1.4,>=1.3 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Using cached text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\r\nCollecting torchmetrics<1.8,>=1.2.0 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Using cached torchmetrics-1.7.3-py3-none-any.whl.metadata (21 kB)\r\nCollecting omegaconf<2.4.0,>=2.1.1 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Using cached omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\r\nCollecting pytorch-metric-learning<2.9,>=1.3.0 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Using cached pytorch_metric_learning-2.8.1-py3-none-any.whl.metadata (18 kB)\r\nCollecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Using cached nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\r\nCollecting nltk<3.9,>=3.4.5 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Using cached nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\r\nCollecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Using cached openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\r\nCollecting defusedxml<0.7.2,>=0.7.1 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\r\nCollecting jinja2<3.2,>=3.0.3 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\r\nCollecting tensorboard<3,>=2.9 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Using cached tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\r\nCollecting pytesseract<0.4,>=0.3.9 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Using cached pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\r\nCollecting nvidia-ml-py3<8.0,>=7.352.0 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Using cached nvidia-ml-py3-7.352.0.tar.gz (19 kB)\r\n  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n\u001B[?25hCollecting pdf2image<1.19,>=1.17.0 (from autogluon.multimodal==1.3.1->autogluon)\r\n  Using cached pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\r\nCollecting catboost<1.3,>=1.2 (from autogluon.tabular[all]==1.3.1->autogluon)\r\n  Using cached catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\r\nCollecting einops<0.9,>=0.7 (from autogluon.tabular[all]==1.3.1->autogluon)\r\n  Using cached einops-0.8.1-py3-none-any.whl.metadata (13 kB)\r\nCollecting xgboost<3.1,>=2.0 (from autogluon.tabular[all]==1.3.1->autogluon)\r\n  Using cached xgboost-3.0.2-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\r\nCollecting fastai<2.9,>=2.3.1 (from autogluon.tabular[all]==1.3.1->autogluon)\r\n  Downloading fastai-2.8.2-py3-none-any.whl.metadata (9.5 kB)\r\nCollecting huggingface-hub[torch] (from autogluon.tabular[all]==1.3.1->autogluon)\r\n  Using cached huggingface_hub-0.33.0-py3-none-any.whl.metadata (14 kB)\r\nCollecting lightgbm<4.7,>=4.0 (from autogluon.tabular[all]==1.3.1->autogluon)\r\n  Using cached lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl.metadata (17 kB)\r\nCollecting spacy<3.9 (from autogluon.tabular[all]==1.3.1->autogluon)\r\n  Downloading spacy-3.8.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\r\nRequirement already satisfied: joblib<2,>=1.1 in /databricks/python3/lib/python3.12/site-packages (from autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (1.4.2)\r\nCollecting pytorch-lightning (from autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\r\n  Downloading pytorch_lightning-2.5.2-py3-none-any.whl.metadata (21 kB)\r\nCollecting gluonts<0.17,>=0.15.0 (from autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\r\n  Downloading gluonts-0.16.1-py3-none-any.whl.metadata (9.8 kB)\r\nCollecting statsforecast<2.0.2,>=1.7.0 (from autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\r\n  Downloading statsforecast-2.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (29 kB)\r\nCollecting mlforecast<0.14,>0.13 (from autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\r\n  Downloading mlforecast-0.13.6-py3-none-any.whl.metadata (12 kB)\r\nCollecting utilsforecast<0.2.11,>=0.2.3 (from autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\r\n  Downloading utilsforecast-0.2.10-py3-none-any.whl.metadata (7.4 kB)\r\nCollecting coreforecast<0.0.16,>=0.0.12 (from autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\r\n  Downloading coreforecast-0.0.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\r\nCollecting fugue>=0.9.0 (from autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\r\n  Downloading fugue-0.9.1-py3-none-any.whl.metadata (18 kB)\r\nCollecting orjson~=3.9 (from autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\r\n  Using cached orjson-3.10.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\r\nRequirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.12/site-packages (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.3.1->autogluon) (24.1)\r\nRequirement already satisfied: pyyaml in /databricks/python3/lib/python3.12/site-packages (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.3.1->autogluon) (6.0.1)\r\nCollecting safetensors>=0.4.3 (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.3.1->autogluon)\r\n  Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\r\nRequirement already satisfied: botocore<1.35.0,>=1.34.69 in /databricks/python3/lib/python3.12/site-packages (from boto3<2,>=1.10->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (1.34.69)\r\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /databricks/python3/lib/python3.12/site-packages (from boto3<2,>=1.10->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (1.0.1)\r\nRequirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /databricks/python3/lib/python3.12/site-packages (from boto3<2,>=1.10->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (0.10.2)\r\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /databricks/python3/lib/python3.12/site-packages (from botocore<1.35.0,>=1.34.69->boto3<2,>=1.10->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (2.9.0.post0)\r\nRequirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /databricks/python3/lib/python3.12/site-packages (from botocore<1.35.0,>=1.34.69->boto3<2,>=1.10->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (1.26.16)\r\nCollecting graphviz (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.3.1->autogluon)\r\n  Downloading graphviz-0.21-py3-none-any.whl.metadata (12 kB)\r\nRequirement already satisfied: plotly in /databricks/python3/lib/python3.12/site-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.3.1->autogluon) (5.22.0)\r\nRequirement already satisfied: six in /usr/lib/python3/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.3.1->autogluon) (1.16.0)\r\nCollecting datasets>=2.0.0 (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\r\nCollecting dill (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\r\nCollecting xxhash (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\r\nCollecting multiprocess (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading multiprocess-0.70.18-py312-none-any.whl.metadata (7.5 kB)\r\nCollecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\r\nRequirement already satisfied: pip in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.3.1->autogluon) (25.1.1)\r\nCollecting fastdownload<2,>=0.0.5 (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.3.1->autogluon)\r\n  Downloading fastdownload-0.0.7-py3-none-any.whl.metadata (5.5 kB)\r\nCollecting fastcore<1.9,>=1.8.0 (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.3.1->autogluon)\r\n  Downloading fastcore-1.8.4-py3-none-any.whl.metadata (3.7 kB)\r\nCollecting fasttransform>=0.0.2 (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.3.1->autogluon)\r\n  Downloading fasttransform-0.0.2-py3-none-any.whl.metadata (7.6 kB)\r\nCollecting fastprogress>=0.2.4 (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.3.1->autogluon)\r\n  Downloading fastprogress-1.0.3-py3-none-any.whl.metadata (5.6 kB)\r\nCollecting plum-dispatch (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.3.1->autogluon)\r\n  Downloading plum_dispatch-2.5.7-py3-none-any.whl.metadata (7.5 kB)\r\nRequirement already satisfied: cloudpickle in /databricks/python3/lib/python3.12/site-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.3.1->autogluon) (2.2.1)\r\nRequirement already satisfied: pydantic<3,>=1.7 in /databricks/python3/lib/python3.12/site-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (2.8.2)\r\nCollecting toolz~=0.10 (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\r\n  Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\r\nRequirement already satisfied: typing-extensions~=4.0 in /databricks/python3/lib/python3.12/site-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (4.11.0)\r\nCollecting future (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.3.1->autogluon)\r\n  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\r\nCollecting py4j (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.3.1->autogluon)\r\n  Downloading py4j-0.10.9.9-py2.py3-none-any.whl.metadata (1.3 kB)\r\nCollecting MarkupSafe>=2.0 (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\r\nCollecting attrs>=22.2.0 (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\r\nCollecting jsonschema-specifications>=2023.03.6 (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\r\nCollecting referencing>=0.28.4 (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\r\nCollecting rpds-py>=0.7.1 (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading rpds_py-0.25.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\r\nCollecting lightning-utilities<2.0,>=0.10.0 (from lightning<2.7,>=2.2->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\r\nCollecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>=2021.05.0->evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading aiohttp-3.12.13-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\r\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning<2.7,>=2.2->autogluon.multimodal==1.3.1->autogluon) (74.0.0)\r\nRequirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (1.2.0)\r\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (0.11.0)\r\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (4.51.0)\r\nRequirement already satisfied: kiwisolver>=1.3.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (1.4.4)\r\nRequirement already satisfied: pyparsing>=2.3.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (3.0.9)\r\nCollecting numba (from mlforecast<0.14,>0.13->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\r\n  Downloading numba-0.61.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\r\nCollecting optuna (from mlforecast<0.14,>0.13->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\r\n  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\r\nCollecting window-ops (from mlforecast<0.14,>0.13->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\r\n  Downloading window_ops-0.0.15-py3-none-any.whl.metadata (6.8 kB)\r\nCollecting gdown>=4.0.0 (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\r\nRequirement already satisfied: click in /databricks/python3/lib/python3.12/site-packages (from nltk<3.9,>=3.4.5->autogluon.multimodal==1.3.1->autogluon) (8.1.7)\r\nCollecting regex>=2021.8.3 (from nltk<3.9,>=3.4.5->autogluon.multimodal==1.3.1->autogluon)\r\n  Using cached regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\r\nCollecting antlr4-python3-runtime==4.9.* (from omegaconf<2.4.0,>=2.1.1->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\r\n  Preparing metadata (setup.py) ... \u001B[?25l-\b \bdone\r\n\u001B[?25hCollecting colorama (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\r\nCollecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\r\nCollecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\r\nCollecting rich (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\r\nCollecting tabulate (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.3.1->autogluon)\r\n  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\r\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.12/site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (2024.1)\r\nCollecting tzdata>=2022.7 (from pandas<2.3.0,>=2.0.0->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon)\r\n  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\r\nRequirement already satisfied: annotated-types>=0.4.0 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (0.7.0)\r\nRequirement already satisfied: pydantic-core==2.20.1 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (2.20.1)\r\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from ray<2.45,>=2.10.0->ray[default]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (3.15.4)\r\nCollecting msgpack<2.0.0,>=1.0.0 (from ray<2.45,>=2.10.0->ray[default]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\r\n  Downloading msgpack-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\r\nRequirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /databricks/python3/lib/python3.12/site-packages (from ray<2.45,>=2.10.0->ray[default]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (4.24.1)\r\nCollecting aiosignal (from ray<2.45,>=2.10.0->ray[default]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\r\n  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\r\nCollecting frozenlist (from ray<2.45,>=2.10.0->ray[default]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\r\n  Downloading frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\r\nCollecting aiohttp_cors (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\r\n  Downloading aiohttp_cors-0.8.1-py3-none-any.whl.metadata (20 kB)\r\nCollecting colorful (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\r\n  Downloading colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)\r\nCollecting py-spy>=0.4.0 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\r\n  Downloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (16 kB)\r\nRequirement already satisfied: grpcio>=1.42.0 in /databricks/python3/lib/python3.12/site-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (1.60.0)\r\nCollecting opencensus (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\r\n  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\r\nCollecting prometheus_client>=0.7.1 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\r\n  Downloading prometheus_client-0.22.1-py3-none-any.whl.metadata (1.9 kB)\r\nCollecting smart_open (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\r\n  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\r\nRequirement already satisfied: virtualenv!=20.21.1,>=20.0.24 in /usr/local/lib/python3.12/dist-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (20.26.2)\r\nCollecting tensorboardX>=1.9 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\r\n  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\r\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.12/site-packages (from requests->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (2.0.4)\r\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.12/site-packages (from requests->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (3.7)\r\nReq\n\n*** WARNING: max output size exceeded, skipping output. ***\n\n━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━\u001B[0m \u001B[32m14/17\u001B[0m [ray]\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━\u001B[0m \u001B[32m14/17\u001B[0m [ray]\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━\u001B[0m \u001B[32m14/17\u001B[0m [ray]\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━\u001B[0m \u001B[32m14/17\u001B[0m [ray]\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━\u001B[0m \u001B[32m14/17\u001B[0m [ray]\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━\u001B[0m \u001B[32m14/17\u001B[0m [ray]\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━\u001B[0m \u001B[32m16/17\u001B[0m [memray]\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━\u001B[0m \u001B[32m16/17\u001B[0m [memray]\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━\u001B[0m \u001B[32m16/17\u001B[0m [memray]\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m17/17\u001B[0m [memray]\n\u001B[?25h\n\u001B[1A\u001B[2KSuccessfully installed anyio-4.9.0 fastapi-0.115.13 h11-0.16.0 httptools-0.6.4 linkify-it-py-2.0.3 mdit-py-plugins-0.4.2 memray-1.17.2 python-dotenv-1.1.0 ray-2.39.0 sniffio-1.3.1 starlette-0.46.2 textual-3.5.0 uc-micro-py-1.0.3 uvicorn-0.34.3 uvloop-0.21.0 watchfiles-1.1.0 websockets-15.0.1\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[33mDEPRECATION: Using the pkg_resources metadata backend is deprecated. pip 26.3 will enforce this behaviour change. A possible replacement is to use the default importlib.metadata backend, by unsetting the _PIP_USE_IMPORTLIB_METADATA environment variable. Discussion can be found at https://github.com/pypa/pip/issues/13317\u001B[0m\u001B[33m\r\n\u001B[0mLooking in indexes: https://download.pytorch.org/whl/cpu\r\nRequirement already satisfied: torch in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (2.6.0)\r\nRequirement already satisfied: torchvision in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (0.21.0)\r\nCollecting torchaudio\r\n  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.7.1%2Bcpu-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\r\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.15.4)\r\nRequirement already satisfied: typing-extensions>=4.10.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from torch) (4.14.0)\r\nRequirement already satisfied: networkx in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from torch) (3.5)\r\nRequirement already satisfied: jinja2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from torch) (3.1.6)\r\nRequirement already satisfied: fsspec in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from torch) (2025.5.1)\r\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from torch) (12.4.127)\r\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from torch) (12.4.127)\r\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from torch) (12.4.127)\r\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from torch) (9.1.0.70)\r\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from torch) (12.4.5.8)\r\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from torch) (11.2.1.3)\r\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from torch) (10.3.5.147)\r\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from torch) (11.6.1.9)\r\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from torch) (12.3.1.170)\r\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from torch) (0.6.2)\r\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from torch) (2.21.5)\r\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from torch) (12.4.127)\r\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from torch) (12.4.127)\r\nRequirement already satisfied: triton==3.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from torch) (3.2.0)\r\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (74.0.0)\r\nRequirement already satisfied: sympy==1.13.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from torch) (1.13.1)\r\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\r\nRequirement already satisfied: numpy in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from torchvision) (2.1.3)\r\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /databricks/python3/lib/python3.12/site-packages (from torchvision) (10.3.0)\r\nINFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\r\n  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.7.0%2Bcpu-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\r\n  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.6.0%2Bcpu-cp312-cp312-linux_x86_64.whl.metadata (6.6 kB)\r\nRequirement already satisfied: MarkupSafe>=2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\r\nDownloading https://download.pytorch.org/whl/cpu/torchaudio-2.6.0%2Bcpu-cp312-cp312-linux_x86_64.whl (1.7 MB)\r\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/1.7 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━\u001B[0m \u001B[32m1.6/1.7 MB\u001B[0m \u001B[31m105.1 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━\u001B[0m \u001B[32m1.6/1.7 MB\u001B[0m \u001B[31m105.1 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.7/1.7 MB\u001B[0m \u001B[31m3.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n\u001B[?25hInstalling collected packages: torchaudio\r\nSuccessfully installed torchaudio-2.6.0+cpu\r\n\u001B[33mDEPRECATION: Using the pkg_resources metadata backend is deprecated. pip 26.3 will enforce this behaviour change. A possible replacement is to use the default importlib.metadata backend, by unsetting the _PIP_USE_IMPORTLIB_METADATA environment variable. Discussion can be found at https://github.com/pypa/pip/issues/13317\u001B[0m\u001B[33m\n\u001B[0mCollecting fastai==2.7.19\n  Downloading fastai-2.7.19-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: pip in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from fastai==2.7.19) (25.1.1)\nRequirement already satisfied: packaging in /databricks/python3/lib/python3.12/site-packages (from fastai==2.7.19) (24.1)\nRequirement already satisfied: fastdownload<2,>=0.0.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from fastai==2.7.19) (0.0.7)\nCollecting fastcore<1.8,>=1.5.29 (from fastai==2.7.19)\n  Downloading fastcore-1.7.29-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: torchvision>=0.11 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from fastai==2.7.19) (0.21.0)\nRequirement already satisfied: matplotlib in /databricks/python3/lib/python3.12/site-packages (from fastai==2.7.19) (3.8.4)\nRequirement already satisfied: pandas in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from fastai==2.7.19) (2.2.3)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.12/site-packages (from fastai==2.7.19) (2.32.2)\nRequirement already satisfied: pyyaml in /databricks/python3/lib/python3.12/site-packages (from fastai==2.7.19) (6.0.1)\nRequirement already satisfied: fastprogress>=0.2.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from fastai==2.7.19) (1.0.3)\nRequirement already satisfied: pillow>=9.0.0 in /databricks/python3/lib/python3.12/site-packages (from fastai==2.7.19) (10.3.0)\nRequirement already satisfied: scikit-learn in /databricks/python3/lib/python3.12/site-packages (from fastai==2.7.19) (1.4.2)\nRequirement already satisfied: scipy in /databricks/python3/lib/python3.12/site-packages (from fastai==2.7.19) (1.13.1)\nRequirement already satisfied: spacy<4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from fastai==2.7.19) (3.8.7)\nRequirement already satisfied: torch<2.7,>=1.10 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from fastai==2.7.19) (2.6.0)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from spacy<4->fastai==2.7.19) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from spacy<4->fastai==2.7.19) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from spacy<4->fastai==2.7.19) (1.0.13)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from spacy<4->fastai==2.7.19) (2.0.11)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from spacy<4->fastai==2.7.19) (3.0.10)\nRequirement already satisfied: thinc<8.4.0,>=8.3.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from spacy<4->fastai==2.7.19) (8.3.6)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from spacy<4->fastai==2.7.19) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from spacy<4->fastai==2.7.19) (2.5.1)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from spacy<4->fastai==2.7.19) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from spacy<4->fastai==2.7.19) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from spacy<4->fastai==2.7.19) (0.16.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from spacy<4->fastai==2.7.19) (4.67.1)\nRequirement already satisfied: numpy>=1.19.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from spacy<4->fastai==2.7.19) (2.1.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /databricks/python3/lib/python3.12/site-packages (from spacy<4->fastai==2.7.19) (2.8.2)\nRequirement already satisfied: jinja2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from spacy<4->fastai==2.7.19) (3.1.6)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy<4->fastai==2.7.19) (74.0.0)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from spacy<4->fastai==2.7.19) (3.5.0)\nRequirement already satisfied: language-data>=1.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<4->fastai==2.7.19) (1.3.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /databricks/python3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai==2.7.19) (0.7.0)\nRequirement already satisfied: pydantic-core==2.20.1 in /databricks/python3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai==2.7.19) (2.20.1)\nRequirement already satisfied: typing-extensions>=4.6.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai==2.7.19) (4.14.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.12/site-packages (from requests->fastai==2.7.19) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.12/site-packages (from requests->fastai==2.7.19) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.12/site-packages (from requests->fastai==2.7.19) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.12/site-packages (from requests->fastai==2.7.19) (2024.6.2)\nRequirement already satisfied: blis<1.4.0,>=1.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy<4->fastai==2.7.19) (1.3.0)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy<4->fastai==2.7.19) (0.1.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<2.7,>=1.10->fastai==2.7.19) (3.15.4)\nRequirement already satisfied: networkx in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from torch<2.7,>=1.10->fastai==2.7.19) (3.5)\nRequirement already satisfied: fsspec in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from torch<2.7,>=1.10->fastai==2.7.19) (2025.5.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from torch<2.7,>=1.10->fastai==2.7.19) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from torch<2.7,>=1.10->fastai==2.7.19) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from torch<2.7,>=1.10->fastai==2.7.19) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from torch<2.7,>=1.10->fastai==2.7.19) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from torch<2.7,>=1.10->fastai==2.7.19) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from torch<2.7,>=1.10->fastai==2.7.19) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from torch<2.7,>=1.10->fastai==2.7.19) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from torch<2.7,>=1.10->fastai==2.7.19) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from torch<2.7,>=1.10->fastai==2.7.19) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from torch<2.7,>=1.10->fastai==2.7.19) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from torch<2.7,>=1.10->fastai==2.7.19) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from torch<2.7,>=1.10->fastai==2.7.19) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from torch<2.7,>=1.10->fastai==2.7.19) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from torch<2.7,>=1.10->fastai==2.7.19) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from torch<2.7,>=1.10->fastai==2.7.19) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from sympy==1.13.1->torch<2.7,>=1.10->fastai==2.7.19) (1.3.0)\nRequirement already satisfied: click>=8.0.0 in /databricks/python3/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai==2.7.19) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai==2.7.19) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai==2.7.19) (14.0.0)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai==2.7.19) (0.21.1)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai==2.7.19) (7.1.0)\nRequirement already satisfied: wrapt in /databricks/python3/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<4->fastai==2.7.19) (1.14.1)\nRequirement already satisfied: marisa-trie>=1.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4->fastai==2.7.19) (1.2.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai==2.7.19) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /databricks/python3/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai==2.7.19) (2.15.1)\nRequirement already satisfied: mdurl~=0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai==2.7.19) (0.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from jinja2->spacy<4->fastai==2.7.19) (3.0.2)\nRequirement already satisfied: contourpy>=1.0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from matplotlib->fastai==2.7.19) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.12/site-packages (from matplotlib->fastai==2.7.19) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.12/site-packages (from matplotlib->fastai==2.7.19) (4.51.0)\nRequirement already satisfied: kiwisolver>=1.3.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib->fastai==2.7.19) (1.4.4)\nRequirement already satisfied: pyparsing>=2.3.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib->fastai==2.7.19) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /databricks/python3/lib/python3.12/site-packages (from matplotlib->fastai==2.7.19) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib->fastai==2.7.19) (1.16.0)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.12/site-packages (from pandas->fastai==2.7.19) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from pandas->fastai==2.7.19) (2025.2)\nRequirement already satisfied: joblib>=1.2.0 in /databricks/python3/lib/python3.12/site-packages (from scikit-learn->fastai==2.7.19) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages (from scikit-learn->fastai==2.7.19) (3.6.0)\nDownloading fastai-2.7.19-py3-none-any.whl (234 kB)\nDownloading fastcore-1.7.29-py3-none-any.whl (84 kB)\nInstalling collected packages: fastcore, fastai\n\u001B[?25l\n\u001B[2K  Attempting uninstall: fastcore\n\n\u001B[2K    Found existing installation: fastcore 1.8.4\n\n\u001B[2K    Uninstalling fastcore-1.8.4:\n\n\u001B[2K      Successfully uninstalled fastcore-1.8.4\n\n\u001B[2K  Attempting uninstall: fastai\n\n\u001B[2K    Found existing installation: fastai 2.8.2\n\n\u001B[2K    Uninstalling fastai-2.8.2:\n\n\u001B[2K      Successfully uninstalled fastai-2.8.2\n\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1/2\u001B[0m [fastai]\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1/2\u001B[0m [fastai]\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2/2\u001B[0m [fastai]\n\u001B[?25h\n\u001B[1A\u001B[2KSuccessfully installed fastai-2.7.19 fastcore-1.7.29\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --upgrade pip\n",
    "!python -m pip install autogluon imbalanced-learn loguru\n",
    "!pip install -U ray[data,train,tune,serve]==2.39.0\n",
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install -U fastai==2.7.19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b903f91-4f95-4105-8a1d-d0ca72ef4c2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "271677db-fa0c-4eef-b27d-572d8236ab42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow; mlflow.autolog(disable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43967473-9f4c-4918-8364-b2ea8353a234",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from loguru import logger\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4344f5d-506a-4dde-adcd-8c658585f0a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Classification with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc6313cf-f69d-4419-831a-a462e0240d9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-06-23 06:05:11.781\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m32\u001B[0m - \u001B[1mTrain data shape: (1534, 26)\u001B[0m\n\u001B[32m2025-06-23 06:05:11.782\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m33\u001B[0m - \u001B[1mTest data shape: (658, 26)\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# Load ML dataset\n",
    "ml_df_class = spark.table('hive_metastore.default.hse_cc_pred_ml').toPandas().drop(columns=['number_of_near_miss_incidents'])\n",
    "\n",
    "# Create training and test datasets\n",
    "label = 'is_near_miss'\n",
    "keys = ['production_date']\n",
    "X = ml_df_class.drop(columns=[label]+keys)\n",
    "y = ml_df_class[label]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)\n",
    "\n",
    "# Use standard scaling\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "# Solve class imbalance using SMOTE\n",
    "# logger.info(f'Class distribution before SMOTE: {Counter(y_train)}')\n",
    "# sm = SMOTE(random_state=42)\n",
    "# X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "# logger.info(f'Class distribution after SMOTE: {Counter(y_train)}')\n",
    "\n",
    "# Prepare the datasets for Autogluon\n",
    "train_data = pd.DataFrame(X_train, columns=X.columns)\n",
    "train_data[label] = y_train.values\n",
    "\n",
    "test_data = pd.DataFrame(X_test, columns=X.columns)\n",
    "test_data[label] = y_test.values\n",
    "\n",
    "train_data_auto = TabularDataset(train_data)\n",
    "test_data_auto = TabularDataset(test_data)\n",
    "\n",
    "logger.info(f\"Train data shape: {train_data_auto.shape}\")\n",
    "logger.info(f\"Test data shape: {test_data_auto.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee5bf665-7593-4520-88b5-3eda96cb976b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# label = 'is_near_miss'\n",
    "# train_data_auto = spark.table('hive_metastore.groupdb_rakona.hse_cc_inc_pred_ml_train').toPandas()\n",
    "# test_data_auto = spark.table('hive_metastore.groupdb_rakona.hse_cc_inc_pred_ml_test').toPandas()\n",
    "\n",
    "# print(f\"Train data shape: {train_data_auto.shape}\")\n",
    "# print(f\"Test data shape: {test_data_auto.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a6c93fa-0f8f-483b-a770-7e40d0fc5079",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250623_060512\"\nVerbosity: 2 (Standard Logging)\n=================== System Info ===================\nAutoGluon Version:  1.3.1\nPython Version:     3.12.3\nOperating System:   Linux\nPlatform Machine:   x86_64\nPlatform Version:   #33~22.04.1-Ubuntu SMP Fri Apr 25 06:39:10 UTC 2025\nCPU Count:          8\nMemory Avail:       39.92 GB / 57.39 GB (69.6%)\nDisk Space Avail:   10.00 GB / 10.00 GB (100.0%)\n\tWARNING: Available disk space is low and there is a risk that AutoGluon will run out of disk during fit, causing an exception. \n\tWe recommend a minimum available disk space of 10 GB, and large datasets may require more.\n===================================================\nPresets specified: ['best_quality']\nSetting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\nStack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\nDyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n2025-06-23 06:05:14,477\tINFO worker.py:1810 -- Started a local Ray instance. View the dashboard at \u001B[1m\u001B[32mhttp://127.0.0.1:8265 \u001B[39m\u001B[22m\n\t\tContext path: \"/Workspace/Users/mubeen.am@pg.com/Port Qasim HSE Command Center V2/AutogluonModels/ag-20250623_060512/ds_sub_fit/sub_fit_ho\"\n\u001B[36m(_dystack pid=6031)\u001B[0m Running DyStack sub-fit ...\n\u001B[36m(_dystack pid=6031)\u001B[0m Beginning AutoGluon training ... Time limit = 897s\n\u001B[36m(_dystack pid=6031)\u001B[0m AutoGluon will save models to \"/Workspace/Users/mubeen.am@pg.com/Port Qasim HSE Command Center V2/AutogluonModels/ag-20250623_060512/ds_sub_fit/sub_fit_ho\"\n\u001B[36m(_dystack pid=6031)\u001B[0m Train Data Rows:    1363\n\u001B[36m(_dystack pid=6031)\u001B[0m Train Data Columns: 25\n\u001B[36m(_dystack pid=6031)\u001B[0m Label Column:       is_near_miss\n\u001B[36m(_dystack pid=6031)\u001B[0m Problem Type:       binary\n\u001B[36m(_dystack pid=6031)\u001B[0m Preprocessing data ...\n\u001B[36m(_dystack pid=6031)\u001B[0m Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n\u001B[36m(_dystack pid=6031)\u001B[0m Using Feature Generators to preprocess the data ...\n\u001B[36m(_dystack pid=6031)\u001B[0m Fitting AutoMLPipelineFeatureGenerator...\n\u001B[36m(_dystack pid=6031)\u001B[0m \tAvailable Memory:                    39829.24 MB\n\u001B[36m(_dystack pid=6031)\u001B[0m \tTrain Data (Original)  Memory Usage: 0.40 MB (0.0% of available memory)\n\u001B[36m(_dystack pid=6031)\u001B[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n\u001B[36m(_dystack pid=6031)\u001B[0m \tStage 1 Generators:\n\u001B[36m(_dystack pid=6031)\u001B[0m \t\tFitting AsTypeFeatureGenerator...\n\u001B[36m(_dystack pid=6031)\u001B[0m \t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n\u001B[36m(_dystack pid=6031)\u001B[0m \tStage 2 Generators:\n\u001B[36m(_dystack pid=6031)\u001B[0m \t\tFitting FillNaFeatureGenerator...\n\u001B[36m(_dystack pid=6031)\u001B[0m \tStage 3 Generators:\n\u001B[36m(_dystack pid=6031)\u001B[0m \t\tFitting IdentityFeatureGenerator...\n\u001B[36m(_dystack pid=6031)\u001B[0m \t\tFitting CategoryFeatureGenerator...\n\u001B[36m(_dystack pid=6031)\u001B[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n\u001B[36m(_dystack pid=6031)\u001B[0m \tStage 4 Generators:\n\u001B[36m(_dystack pid=6031)\u001B[0m \t\tFitting DropUniqueFeatureGenerator...\n\u001B[36m(_dystack pid=6031)\u001B[0m \tStage 5 Generators:\n\u001B[36m(_dystack pid=6031)\u001B[0m \t\tFitting DropDuplicatesFeatureGenerator...\n\u001B[36m(_dystack pid=6031)\u001B[0m \tUseless Original Features (Count: 1): ['breakdowns']\n\u001B[36m(_dystack pid=6031)\u001B[0m \t\tThese features carry no predictive signal and should be manually investigated.\n\u001B[36m(_dystack pid=6031)\u001B[0m \t\tThis is typically a feature which has the same value for all rows.\n\u001B[36m(_dystack pid=6031)\u001B[0m \t\tThese features do not need to be present at inference time.\n\u001B[36m(_dystack pid=6031)\u001B[0m \tTypes of features in original data (raw dtype, special dtypes):\n\u001B[36m(_dystack pid=6031)\u001B[0m \t\t('float', [])  : 19 | ['constrained_stops', 'planned_count', 'unplanned_count', 'duration_sum', 'constrained_stops_per_day', ...]\n\u001B[36m(_dystack pid=6031)\u001B[0m \t\t('int', [])    :  3 | ['num_resolved_in_24_hours', 'num_unresolved_in_7_days', 'num_unresolved_in_30_days']\n\u001B[36m(_dystack pid=6031)\u001B[0m \t\t('object', []) :  2 | ['department_name', 'line_name']\n\u001B[36m(_dystack pid=6031)\u001B[0m \tTypes of features in processed data (raw dtype, special dtypes):\n\u001B[36m(_dystack pid=6031)\u001B[0m \t\t('category', [])  :  2 | ['department_name', 'line_name']\n\u001B[36m(_dystack pid=6031)\u001B[0m \t\t('float', [])     : 18 | ['constrained_stops', 'planned_count', 'unplanned_count', 'duration_sum', 'constrained_stops_per_day', ...]\n\u001B[36m(_dystack pid=6031)\u001B[0m \t\t('int', [])       :  3 | ['num_resolved_in_24_hours', 'num_unresolved_in_7_days', 'num_unresolved_in_30_days']\n\u001B[36m(_dystack pid=6031)\u001B[0m \t\t('int', ['bool']) :  1 | ['compliance_perc']\n\u001B[36m(_dystack pid=6031)\u001B[0m \t0.0s = Fit runtime\n\u001B[36m(_dystack pid=6031)\u001B[0m \t24 features in original data used to generate 24 features in processed data.\n\u001B[36m(_dystack pid=6031)\u001B[0m \tTrain Data (Processed) Memory Usage: 0.22 MB (0.0% of available memory)\n\u001B[36m(_dystack pid=6031)\u001B[0m Data preprocessing and feature engineering runtime = 0.04s ...\n\u001B[36m(_dystack pid=6031)\u001B[0m AutoGluon will gauge predictive performance using evaluation metric: 'f1'\n\u001B[36m(_dystack pid=6031)\u001B[0m \tTo change this, specify the eval_metric parameter of Predictor()\n\u001B[36m(_dystack pid=6031)\u001B[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n\u001B[36m(_dystack pid=6031)\u001B[0m User-specified model hyperparameters to be fit:\n\u001B[36m(_dystack pid=6031)\u001B[0m {\n\u001B[36m(_dystack pid=6031)\u001B[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n\u001B[36m(_dystack pid=6031)\u001B[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n\u001B[36m(_dystack pid=6031)\u001B[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n\u001B[36m(_dystack pid=6031)\u001B[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n\u001B[36m(_dystack pid=6031)\u001B[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n\u001B[36m(_dystack pid=6031)\u001B[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n\u001B[36m(_dystack pid=6031)\u001B[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n\u001B[36m(_dystack pid=6031)\u001B[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n\u001B[36m(_dystack pid=6031)\u001B[0m }\n\u001B[36m(_dystack pid=6031)\u001B[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n\u001B[36m(_dystack pid=6031)\u001B[0m Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n\u001B[36m(_dystack pid=6031)\u001B[0m Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 597.80s of the 896.91s of remaining time.\n\u001B[36m(_dystack pid=6031)\u001B[0m \t0.1951\t = Validation score   (f1)\n\u001B[36m(_dystack pid=6031)\u001B[0m \t0.0s\t = Training   runtime\n\u001B[36m(_dystack pid=6031)\u001B[0m \t0.06s\t = Validation runtime\n\u001B[36m(_dystack pid=6031)\u001B[0m Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 595.72s of the 894.83s of remaining time.\n\u001B[36m(_dystack pid=6031)\u001B[0m \t0.2381\t = Validation score   (f1)\n\u001B[36m(_dystack pid=6031)\u001B[0m \t0.0s\t = Training   runtime\n\u001B[36m(_dystack pid=6031)\u001B[0m \t0.0s\t = Validation runtime\n\u001B[36m(_dystack pid=6031)\u001B[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 594.72s of the 893.83s of remaining time.\n\u001B[36m(_dystack pid=6031)\u001B[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n\u001B[36m(_dystack pid=6031)\u001B[0m \t0.25\t = Validation score   (f1)\n\u001B[36m(_dystack pid=6031)\u001B[0m \t3.04s\t = Training   runtime\n\u001B[36m(_dystack pid=6031)\u001B[0m \t0.03s\t = Validation runtime\n\u001B[36m(_dystack pid=6031)\u001B[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 587.12s of the 886.23s of remaining time.\n\u001B[36m(_dystack pid=6031)\u001B[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n\u001B[36m(_dystack pid=6031)\u001B[0m \t0.2941\t = Validation score   (f1)\n\u001B[36m(_dystack pid=6031)\u001B[0m \t1.07s\t = Training   runtime\n\u001B[36m(_dystack pid=6031)\u001B[0m \t0.02s\t = Validation runtime\n\u001B[36m(_dystack pid=6031)\u001B[0m Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 583.04s of the 882.16s of remaining time.\n\u001B[36m(_dystack pid=6031)\u001B[0m \t0.0645\t = Validation score   (f1)\n\u001B[36m(_dystack pid=6031)\u001B[0m \t0.95s\t = Training   runtime\n\u001B[36m(_dystack pid=6031)\u001B[0m \t0.13s\t = Validation runtime\n\u001B[36m(_dystack pid=6031)\u001B[0m Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 581.08s of the 880.20s of remaining time.\n\u001B[36m(_dystack pid=6031)\u001B[0m \t0.1212\t = Validation score   (f1)\n\u001B[36m(_dystack pid=6031)\u001B[0m \t0.92s\t = Training   runtime\n\u001B[36m(_dystack pid=6031)\u001B[0m \t0.08s\t = Validation runtime\n\u001B[36m(_dystack pid=6031)\u001B[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 578.23s of the 877.34s of remaining time.\n\u001B[36m(_dystack pid=6031)\u001B[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.03%)\n\u001B[36m(_dystack pid=6031)\u001B[0m \t0.0\t = Validation score   (f1)\n\u001B[36m(_dystack pid=6031)\u001B[0m \t2.52s\t = Training   runtime\n\u001B[36m(_dystack pid=6031)\u001B[0m \t0.02s\t = Validation runtime\n\u001B[36m(_dystack pid=6031)\u001B[0m Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 570.06s of the 869.17s of remaining time.\n\u001B[36m(_dystack pid=6031)\u001B[0m \t0.0\t = Validation score   (f1)\n\u001B[36m(_dystack pid=6031)\u001B[0m \t0.64s\t = Training   runtime\n\u001B[36m(_dystack pid=6031)\u001B[0m \t0.23s\t = Validation runtime\n\u001B[36m(_dystack pid=6031)\u001B[0m Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 566.95s of the 866.07s of remaining time.\n\u001B[36m(_dystack pid=6031)\u001B[0m \t0.1818\t = Validation score   (f1)\n\u001B[36m(_dystack pid=6031)\u001B[0m \t0.48s\t = Training   runtime\n\u001B[36m(_dystack pid=6031)\u001B[0m \t0.08s\t = Validation runtime\n\u001B[36m(_dystack pid=6031)\u001B[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 564.13s of the 863.25s of remaining time.\n\u001B[36m(_dystack pid=6031)\u001B[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n\u001B[36m(_ray_fit pid=9169)\u001B[0m No improvement since epoch 3: early stopping\n\u001B[36m(_dystack pid=6031)\u001B[0m \t0.4839\t = Validation score   (f1)\n\u001B[36m(_dystack pid=6031)\u001B[0m \t4.31s\t = Training   runtime\n\u001B[36m(_dystack pid=6031)\u001B[0m \t0.06s\t = Validation runtime\n\u001B[36m(_dystack pid=6031)\u001B[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 556.54s of the 855.66s of remaining time.\n\u001B[36m(_dystack pid=6031)\u001B[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.05%)\n\u001B[36m(_dystack pid=6031)\u001B[0m \t0.2581\t = Validation score   (f1)\n\u001B[36m(_dystack pid=6031)\u001B[0m \t3.32s\t = Training   runtime\n\u001B[36m(_dystack pid=6031)\u001B[0m \t0.08s\t = Validation runtime\n\u001B[36m(_ray_fit pid=9168)\u001B[0m No improvement since epoch 7: early stopping\n\u001B[36m(_dystack pid=6031)\u001B[0m Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 543.02s of the 842.13s of remaining time.\n\u001B[36m(_dystack pid=6031)\u001B[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n\u001B[36m(_dystack pid=6031)\u001B[0m \tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n\u001B[36m(_dystack pid=6031)\u001B[0m \t\t\u001B[36mray::_ray_fit()\u001B[39m (pid=10443, ip=10.99.12.6)\n\u001B[36m(_dystack pid=6031)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n\u001B[36m(_dystack pid=6031)\u001B[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n\u001B[36m(_dystack pid=6031)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n\u001B[36m(_dystack pid=6031)\u001B[0m     out = self._fit(**kwargs)\n\u001B[36m(_dystack pid=6031)\u001B[0m           ^^^^^^^^^^^^^^^^^^^\n\u001B[36m(_dystack pid=6031)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n\u001B[36m(_dystack pid=6031)\u001B[0m     train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n\u001B[36m(_dystack pid=6031)\u001B[0m                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001B[36m(_dystack pid=6031)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n\u001B[36m(_dystack pid=6031)\u001B[0m     dataset = self._process_train_data(\n\u001B[36m(_dystack pid=6031)\u001B[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001B[36m(_dystack pid=6031)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n\u001B[36m(_dystack pid=6031)\u001B[0m     self.processor = create_preprocessor(\n\u001B[36m(_dystack pid=6031)\u001B[0m                      ^^^^^^^^^^^^^^^^^^^^\n\u001B[36m(_dystack pid=6031)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n\u001B[36m(_dystack pid=6031)\u001B[0m     return ColumnTransformer(\n\u001B[36m(_dystack pid=6031)\u001B[0m            ^^^^^^^^^^^^^^^^^^\n\u001B[36m(_dystack pid=6031)\u001B[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n\u001B[36m(_dystack pid=6031)\u001B[0m Detailed Traceback:\n\u001B[36m(_dystack pid=6031)\u001B[0m Traceback (most recent call last):\n\u001B[36m(_dystack pid=6031)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2169, in _train_and_save\n\u001B[36m(_dystack pid=6031)\u001B[0m     model = self._train_single(**model_fit_kwargs)\n\u001B[36m(_dystack pid=6031)\u001B[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001B[36m(_dystack pid=6031)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2055, in _train_single\n\u001B[36m(_dystack pid=6031)\u001B[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n\u001B[36m(_dystack pid=6031)\u001B[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001B[36m(_dystack pid=6031)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n\u001B[36m(_dystack pid=6031)\u001B[0m     out = self._fit(**kwargs)\n\u001B[36m(_dystack pid=6031)\u001B[0m           ^^^^^^^^^^^^^^^^^^^\n\u001B[36m(_dystack pid=6031)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n\u001B[36m(_dystack pid=6031)\u001B[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n\u001B[36m(_dystack pid=6031)\u001B[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001B[36m(_dystack pid=6031)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n\u001B[36m(_dystack pid=6031)\u001B[0m     self._fit_folds(\n\u001B[36m(_dystack pid=6031)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n\u001B[36m(_dystack pid=6031)\u001B[0m     fold_fitting_strategy.after_all_folds_scheduled()\n\u001B[36m(_dystack pid=6031)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n\u001B[36m(_dystack pid=6031)\u001B[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n\u001B[36m(_dystack pid=6031)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n\u001B[36m(_dystack pid=6031)\u001B[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n\u001B[36m(_dystack pid=6031)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n\u001B[36m(_dystack pid=6031)\u001B[0m     raise processed_exception\n\u001B[36m(_dystack pid=6031)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n\u001B[36m(_dystack pid=6031)\u001B[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n\u001B[36m(_dystack pid=6031)\u001B[0m                                                                                                                                      ^^^^^^^^^^^^^^^^^^^^^^\n\u001B[36m(_dystack pid=6031)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n\u001B[36m(_dystack pid=6031)\u001B[0m     return fn(*args, **kwargs)\n\u001B[36m(_dystack pid=6031)\u001B[0m            ^^^^^^^^^^^^^^^^^^^\n\u001B[36m(_dystack pid=6031)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n\u001B[36m(_dystack pid=6031)\u001B[0m     return func(*args, **kwargs)\n\u001B[36m(_dystack pid=6031)\u001B[0m            ^^^^^^^^^^^^^^^^^^^^^\n\u001B[36m(_dystack pid=6031)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/ray/_private/worker.py\", line 2753, in get\n\u001B[36m(_dystack pid=6031)\u001B[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n\u001B[36m(_dystack pid=6031)\u001B[0m                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001B[36m(_dystack pid=6031)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/ray/_private/worker.py\", line 904, in get_objects\n\u001B[36m(_dystack pid=6031)\u001B[0m     raise value.as_instanceof_cause()\n\u001B[36m(_dystack pid=6031)\u001B[0m ray.exceptions.RayTaskError(TypeError): \u001B[36mray::_ray_fit()\u001B[39m (pid=10443, ip=10.99.12.6)\n\u001B[36m(_dystack pid=6031)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n\u001B[36m(_dystack pid=6031)\u001B[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n\u001B[36m(_dystack pid=6031)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n\u001B[36m(_dystack pid=6031)\u001B[0m     out = self._fit(**kwargs)\n\u001B[36m(_dystack pid=6031)\u001B[0m           ^^^^^^^^^^^^^^^^^^^\n\u001B[36m(_dystack pid=6031)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n\u001B[36m(_dystack pid=6031)\u001B[0m     train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n\u001B[36m(_dystack pid=6031)\u001B[0m                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001B[36m(_dystack pid=6031)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n\u001B[36m(_dystack pid=6031)\u001B[0m     dataset = self._process_train_data(\n\u001B[36m(_dystack pid=6031)\u001B[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001B[36m(_dystack pid=6031)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n\u001B[36m(_dystack pid=6031)\u001B[0m     self.processor = create_preprocessor(\n\u001B[36m(_dystack pid=6031)\u001B[0m                      ^^^^^^^^^^^^^^^^^^^^\n\u001B[36m(_dystack pid=6031)\u001B[0m   File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n\u001B[36m(_dystack pid=6031)\u001B[0m     return ColumnTransformer(\n\u001B[36m(_dystack pid=6031)\u001B[0m            ^^^^^^^^^^^^^^^^^^\n\u001B[36m(_dystack pid=6031)\u001B[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n\u001B[36m(_dystack pid=6031)\u001B[0m Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 535.65s of the 834.77s of remaining time.\n\u001B[36m(_dystack pid=6031)\u001B[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFit\n\n*** WARNING: max output size exceeded, skipping output. ***\n\ntask. Check python-core-worker-*.log files for more information.\n2025-06-23 07:01:40,253\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n2025-06-23 07:01:40,254\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n2025-06-23 07:01:40,255\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n2025-06-23 07:01:40,256\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n\t0.5333\t = Validation score   (f1)\n\t73.06s\t = Training   runtime\n\t0.19s\t = Validation runtime\nFitting model: NeuralNetFastAI_r37_BAG_L2 ... Training model for up to 141.95s of the 140.96s of remaining time.\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n\t0.6441\t = Validation score   (f1)\n\t8.28s\t = Training   runtime\n\t0.14s\t = Validation runtime\nFitting model: NeuralNetTorch_r197_BAG_L2 ... Training model for up to 130.45s of the 129.46s of remaining time.\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n\tWarning: Exception caused NeuralNetTorch_r197_BAG_L2 to fail during training... Skipping this model.\n\t\t\u001B[36mray::_ray_fit()\u001B[39m (pid=180594, ip=10.99.12.6)\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n    out = self._fit(**kwargs)\n          ^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n    train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n    dataset = self._process_train_data(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n    self.processor = create_preprocessor(\n                     ^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n    return ColumnTransformer(\n           ^^^^^^^^^^^^^^^^^^\nTypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\nDetailed Traceback:\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2169, in _train_and_save\n    model = self._train_single(**model_fit_kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2055, in _train_single\n    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n    out = self._fit(**kwargs)\n          ^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n    self._fit_folds(\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n    fold_fitting_strategy.after_all_folds_scheduled()\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n    self._process_fold_results(finished, unfinished, fold_ctx)\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n    raise processed_exception\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n                                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/ray/_private/worker.py\", line 2753, in get\n    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/ray/_private/worker.py\", line 904, in get_objects\n    raise value.as_instanceof_cause()\nray.exceptions.RayTaskError(TypeError): \u001B[36mray::_ray_fit()\u001B[39m (pid=180594, ip=10.99.12.6)\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n    out = self._fit(**kwargs)\n          ^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n    train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n    dataset = self._process_train_data(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n    self.processor = create_preprocessor(\n                     ^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n    return ColumnTransformer(\n           ^^^^^^^^^^^^^^^^^^\nTypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\nFitting model: CatBoost_r49_BAG_L2 ... Training model for up to 121.21s of the 120.22s of remaining time.\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.20%)\n2025-06-23 07:03:18,303\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n2025-06-23 07:03:18,305\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n2025-06-23 07:03:18,307\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n2025-06-23 07:03:18,307\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n2025-06-23 07:03:18,308\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n2025-06-23 07:03:18,309\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n2025-06-23 07:03:18,310\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n\t0.5833\t = Validation score   (f1)\n\t2.43s\t = Training   runtime\n\t0.03s\t = Validation runtime\nFitting model: ExtraTrees_r49_BAG_L2 ... Training model for up to 114.52s of the 113.53s of remaining time.\n\t0.4286\t = Validation score   (f1)\n\t0.84s\t = Training   runtime\n\t0.12s\t = Validation runtime\nFitting model: LightGBM_r143_BAG_L2 ... Training model for up to 112.11s of the 111.12s of remaining time.\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.39%)\n\t0.5957\t = Validation score   (f1)\n\t5.89s\t = Training   runtime\n\t0.08s\t = Validation runtime\nFitting model: RandomForest_r127_BAG_L2 ... Training model for up to 102.00s of the 101.01s of remaining time.\n\t0.56\t = Validation score   (f1)\n\t1.05s\t = Training   runtime\n\t0.06s\t = Validation runtime\nFitting model: NeuralNetFastAI_r134_BAG_L2 ... Training model for up to 100.08s of the 99.09s of remaining time.\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n\t0.7037\t = Validation score   (f1)\n\t35.53s\t = Training   runtime\n\t0.17s\t = Validation runtime\nFitting model: RandomForest_r34_BAG_L2 ... Training model for up to 60.66s of the 59.67s of remaining time.\n\t0.0\t = Validation score   (f1)\n\t0.47s\t = Training   runtime\n\t0.06s\t = Validation runtime\nFitting model: LightGBM_r94_BAG_L2 ... Training model for up to 59.15s of the 58.16s of remaining time.\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.05%)\n\t0.5\t = Validation score   (f1)\n\t1.54s\t = Training   runtime\n\t0.03s\t = Validation runtime\nFitting model: NeuralNetTorch_r143_BAG_L2 ... Training model for up to 54.95s of the 53.96s of remaining time.\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n\tWarning: Exception caused NeuralNetTorch_r143_BAG_L2 to fail during training... Skipping this model.\n\t\t\u001B[36mray::_ray_fit()\u001B[39m (pid=184756, ip=10.99.12.6)\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n    out = self._fit(**kwargs)\n          ^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n    train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n    dataset = self._process_train_data(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n    self.processor = create_preprocessor(\n                     ^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n    return ColumnTransformer(\n           ^^^^^^^^^^^^^^^^^^\nTypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\nDetailed Traceback:\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2169, in _train_and_save\n    model = self._train_single(**model_fit_kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2055, in _train_single\n    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n    out = self._fit(**kwargs)\n          ^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n    self._fit_folds(\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n    fold_fitting_strategy.after_all_folds_scheduled()\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n    self._process_fold_results(finished, unfinished, fold_ctx)\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n    raise processed_exception\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n                                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/ray/_private/worker.py\", line 2753, in get\n    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/ray/_private/worker.py\", line 904, in get_objects\n    raise value.as_instanceof_cause()\nray.exceptions.RayTaskError(TypeError): \u001B[36mray::_ray_fit()\u001B[39m (pid=184756, ip=10.99.12.6)\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n    out = self._fit(**kwargs)\n          ^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n    train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n    dataset = self._process_train_data(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n    self.processor = create_preprocessor(\n                     ^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-1b22e41a-faac-4f76-83a7-41dc978ddb19/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n    return ColumnTransformer(\n           ^^^^^^^^^^^^^^^^^^\nTypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\nFitting model: CatBoost_r128_BAG_L2 ... Training model for up to 50.49s of the 49.50s of remaining time.\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.61%)\n2025-06-23 07:04:30,334\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n2025-06-23 07:04:30,335\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n2025-06-23 07:04:30,336\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n2025-06-23 07:04:30,337\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n2025-06-23 07:04:30,338\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n2025-06-23 07:04:30,338\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n2025-06-23 07:04:30,339\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n\t0.5116\t = Validation score   (f1)\n\t40.51s\t = Training   runtime\n\t0.04s\t = Validation runtime\nFitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -21.69s of remaining time.\n\tEnsemble Weights: {'NeuralNetFastAI_r11_BAG_L2': 0.667, 'ExtraTrees_r42_BAG_L2': 0.333}\n\t0.717\t = Validation score   (f1)\n\t0.3s\t = Training   runtime\n\t0.0s\t = Validation runtime\nAutoGluon training complete, total runtime = 2244.87s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 155.0 rows/s (192 batch size)\nEnabling decision threshold calibration (calibrate_decision_threshold='auto', metric is valid, problem_type is 'binary')\nCalibrating decision threshold to optimize metric f1 | Checking 51 thresholds...\nCalibrating decision threshold via fine-grained search | Checking 38 thresholds...\n\tBase Threshold: 0.500\t| val: 0.7170\n\tBest Threshold: 0.500\t| val: 0.7170\nTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Workspace/Users/mubeen.am@pg.com/Port Qasim HSE Command Center V2/AutogluonModels/ag-20250623_060512\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=label, eval_metric=\"f1\").fit(\n",
    "    train_data_auto,\n",
    "    # time_limit=600,\n",
    "    presets=\"best_quality\"\n",
    "    # num_bag_folds=5,\n",
    "    # num_stack_levels=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8203c17-1925-462b-949f-ddcf38b5d415",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost_r50_BAG_L1</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>f1</td>\n",
       "      <td>1.258348</td>\n",
       "      <td>0.059675</td>\n",
       "      <td>4.643626</td>\n",
       "      <td>1.258348</td>\n",
       "      <td>0.059675</td>\n",
       "      <td>4.643626</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NeuralNetFastAI_r191_BAG_L2</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.634921</td>\n",
       "      <td>f1</td>\n",
       "      <td>22.920179</td>\n",
       "      <td>1.779616</td>\n",
       "      <td>113.941060</td>\n",
       "      <td>2.318692</td>\n",
       "      <td>0.178860</td>\n",
       "      <td>14.556843</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest_r166_BAG_L1</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.977204</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.355407</td>\n",
       "      <td>0.059912</td>\n",
       "      <td>0.985944</td>\n",
       "      <td>0.355407</td>\n",
       "      <td>0.059912</td>\n",
       "      <td>0.985944</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestGini_BAG_L1</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.977204</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.363959</td>\n",
       "      <td>0.098715</td>\n",
       "      <td>0.826233</td>\n",
       "      <td>0.363959</td>\n",
       "      <td>0.098715</td>\n",
       "      <td>0.826233</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestEntr_BAG_L1</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.977204</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.406090</td>\n",
       "      <td>0.120731</td>\n",
       "      <td>0.910077</td>\n",
       "      <td>0.406090</td>\n",
       "      <td>0.120731</td>\n",
       "      <td>0.910077</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>NeuralNetFastAI_r102_BAG_L2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.963526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>f1</td>\n",
       "      <td>23.110988</td>\n",
       "      <td>1.861397</td>\n",
       "      <td>115.459364</td>\n",
       "      <td>2.509501</td>\n",
       "      <td>0.260641</td>\n",
       "      <td>16.075147</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>XGBoost_r33_BAG_L2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.975684</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.418605</td>\n",
       "      <td>f1</td>\n",
       "      <td>23.350826</td>\n",
       "      <td>1.653194</td>\n",
       "      <td>103.202182</td>\n",
       "      <td>2.749339</td>\n",
       "      <td>0.052438</td>\n",
       "      <td>3.817965</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>NeuralNetFastAI_r11_BAG_L2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.968085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>f1</td>\n",
       "      <td>23.372835</td>\n",
       "      <td>1.836552</td>\n",
       "      <td>114.474643</td>\n",
       "      <td>2.771348</td>\n",
       "      <td>0.235796</td>\n",
       "      <td>15.090425</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>NeuralNetFastAI_r134_BAG_L2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.968085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>f1</td>\n",
       "      <td>23.559485</td>\n",
       "      <td>1.769566</td>\n",
       "      <td>134.918080</td>\n",
       "      <td>2.957998</td>\n",
       "      <td>0.168810</td>\n",
       "      <td>35.533863</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.966565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>f1</td>\n",
       "      <td>23.933435</td>\n",
       "      <td>2.011636</td>\n",
       "      <td>115.749779</td>\n",
       "      <td>0.148109</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>0.304152</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           model  score_test  ...  can_infer  fit_order\n",
       "0            CatBoost_r50_BAG_L1    0.125000  ...       True         28\n",
       "1    NeuralNetFastAI_r191_BAG_L2    0.125000  ...       True        103\n",
       "2       RandomForest_r166_BAG_L1    0.117647  ...       True         63\n",
       "3        RandomForestGini_BAG_L1    0.117647  ...       True          5\n",
       "4        RandomForestEntr_BAG_L1    0.117647  ...       True          6\n",
       "..                           ...         ...  ...        ...        ...\n",
       "137  NeuralNetFastAI_r102_BAG_L2    0.000000  ...       True        109\n",
       "138           XGBoost_r33_BAG_L2    0.000000  ...       True        106\n",
       "139   NeuralNetFastAI_r11_BAG_L2    0.000000  ...       True        117\n",
       "140  NeuralNetFastAI_r134_BAG_L2    0.000000  ...       True        138\n",
       "141          WeightedEnsemble_L3    0.000000  ...       True        142\n",
       "\n",
       "[142 rows x 16 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data_auto, extra_metrics=['accuracy', 'precision', 'recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bfa0814-b535-4e4f-91d5-d3428c316407",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'f1': np.float64(0.125),\n",
       " 'accuracy': 0.9787234042553191,\n",
       " 'balanced_accuracy': np.float64(0.5369111508646393),\n",
       " 'mcc': np.float64(0.15249578439995462),\n",
       " 'roc_auc': np.float64(0.923494335122242),\n",
       " 'precision': np.float64(0.3333333333333333),\n",
       " 'recall': np.float64(0.07692307692307693)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(test_data_auto, model='CatBoost_r50_BAG_L1', silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a06cfe24-a87a-4760-b451-c7c5a6034810",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "These features in provided data are not utilized by the predictor and will be ignored: ['breakdowns']\nComputing feature importance via permutation shuffling for 24 features using 658 rows with 5 shuffle sets...\n\t93.33s\t= Expected runtime (18.67s per shuffle set)\n\t1.84s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>department_name</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line_name</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>constrained_stops</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>planned_count</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unplanned_count</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>planned_stops_per_day</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_defects_yesterday</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unplanned_stops_per_day</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>safe_percentage</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per_resolved_in_24_hours</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_resolved_in_24_hours</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unsafe_percentage</th>\n",
       "      <td>0.098333</td>\n",
       "      <td>0.059628</td>\n",
       "      <td>0.010532</td>\n",
       "      <td>5</td>\n",
       "      <td>0.221109</td>\n",
       "      <td>-0.024443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compliance_perc</th>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.073627</td>\n",
       "      <td>0.047942</td>\n",
       "      <td>5</td>\n",
       "      <td>0.223027</td>\n",
       "      <td>-0.080170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>completed_perc</th>\n",
       "      <td>0.069762</td>\n",
       "      <td>0.075713</td>\n",
       "      <td>0.054207</td>\n",
       "      <td>5</td>\n",
       "      <td>0.225656</td>\n",
       "      <td>-0.086132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_sum</th>\n",
       "      <td>0.067857</td>\n",
       "      <td>0.078246</td>\n",
       "      <td>0.062247</td>\n",
       "      <td>5</td>\n",
       "      <td>0.228967</td>\n",
       "      <td>-0.093253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>constrained_stops_per_day</th>\n",
       "      <td>0.041190</td>\n",
       "      <td>0.076606</td>\n",
       "      <td>0.147773</td>\n",
       "      <td>5</td>\n",
       "      <td>0.198923</td>\n",
       "      <td>-0.116542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_positive_feedbacks</th>\n",
       "      <td>0.004412</td>\n",
       "      <td>0.004027</td>\n",
       "      <td>0.035242</td>\n",
       "      <td>5</td>\n",
       "      <td>0.012704</td>\n",
       "      <td>-0.003881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_corrective_feedbacks</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_unresolved_in_7_days</th>\n",
       "      <td>-0.001667</td>\n",
       "      <td>0.003727</td>\n",
       "      <td>0.813050</td>\n",
       "      <td>5</td>\n",
       "      <td>0.006007</td>\n",
       "      <td>-0.009340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_unresolved_in_30_days</th>\n",
       "      <td>-0.001667</td>\n",
       "      <td>0.003727</td>\n",
       "      <td>0.813050</td>\n",
       "      <td>5</td>\n",
       "      <td>0.006007</td>\n",
       "      <td>-0.009340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per_unresolved_in_30_days</th>\n",
       "      <td>-0.001667</td>\n",
       "      <td>0.003727</td>\n",
       "      <td>0.813050</td>\n",
       "      <td>5</td>\n",
       "      <td>0.006007</td>\n",
       "      <td>-0.009340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_defects</th>\n",
       "      <td>-0.008333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.008333</td>\n",
       "      <td>-0.008333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>completed_audits</th>\n",
       "      <td>-0.008571</td>\n",
       "      <td>0.006322</td>\n",
       "      <td>0.980643</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004445</td>\n",
       "      <td>-0.021588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per_unresolved_in_7_days</th>\n",
       "      <td>-0.010238</td>\n",
       "      <td>0.004259</td>\n",
       "      <td>0.997106</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.001468</td>\n",
       "      <td>-0.019008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            importance    stddev  ...  p99_high   p99_low\n",
       "department_name               0.125000  0.000000  ...  0.125000  0.125000\n",
       "line_name                     0.125000  0.000000  ...  0.125000  0.125000\n",
       "constrained_stops             0.125000  0.000000  ...  0.125000  0.125000\n",
       "planned_count                 0.125000  0.000000  ...  0.125000  0.125000\n",
       "unplanned_count               0.125000  0.000000  ...  0.125000  0.125000\n",
       "planned_stops_per_day         0.125000  0.000000  ...  0.125000  0.125000\n",
       "total_defects_yesterday       0.125000  0.000000  ...  0.125000  0.125000\n",
       "unplanned_stops_per_day       0.125000  0.000000  ...  0.125000  0.125000\n",
       "safe_percentage               0.125000  0.000000  ...  0.125000  0.125000\n",
       "per_resolved_in_24_hours      0.125000  0.000000  ...  0.125000  0.125000\n",
       "num_resolved_in_24_hours      0.125000  0.000000  ...  0.125000  0.125000\n",
       "unsafe_percentage             0.098333  0.059628  ...  0.221109 -0.024443\n",
       "compliance_perc               0.071429  0.073627  ...  0.223027 -0.080170\n",
       "completed_perc                0.069762  0.075713  ...  0.225656 -0.086132\n",
       "duration_sum                  0.067857  0.078246  ...  0.228967 -0.093253\n",
       "constrained_stops_per_day     0.041190  0.076606  ...  0.198923 -0.116542\n",
       "no_of_positive_feedbacks      0.004412  0.004027  ...  0.012704 -0.003881\n",
       "no_of_corrective_feedbacks    0.000000  0.000000  ...  0.000000  0.000000\n",
       "num_unresolved_in_7_days     -0.001667  0.003727  ...  0.006007 -0.009340\n",
       "num_unresolved_in_30_days    -0.001667  0.003727  ...  0.006007 -0.009340\n",
       "per_unresolved_in_30_days    -0.001667  0.003727  ...  0.006007 -0.009340\n",
       "total_defects                -0.008333  0.000000  ... -0.008333 -0.008333\n",
       "completed_audits             -0.008571  0.006322  ...  0.004445 -0.021588\n",
       "per_unresolved_in_7_days     -0.010238  0.004259  ... -0.001468 -0.019008\n",
       "\n",
       "[24 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.feature_importance(test_data_auto, model='CatBoost_r50_BAG_L1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54f6a076-4dc3-4ca2-8e33-2c738bd814b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02-PQ-incidents-ml-class-automl-Jun-25",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}